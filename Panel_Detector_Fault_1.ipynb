{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el modelo ssd7 \n",
    "(https://github.com/pierluigiferrari/ssd_keras#how-to-fine-tune-one-of-the-trained-models-on-your-own-dataset)\n",
    "\n",
    "Training del SSD7 (modelo reducido de SSD). Par√°metros en config_7.json y descargar VGG_ILSVRC_16_layers_fc_reduced.h5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on: \t{'1': 1}\n",
      "\n",
      "WARNING:tensorflow:From /home/dl-desktop/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "OK create model\n",
      "\n",
      "Loading pretrained weights VGG.\n",
      "\n",
      "WARNING:tensorflow:From /home/dl-desktop/Desktop/Rentadrone/ssd_keras-master/keras_loss_function/keras_ssd_loss.py:133: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/dl-desktop/Desktop/Rentadrone/ssd_keras-master/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 400, 400, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 400, 400, 32) 2432        identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 400, 400, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu1 (ELU)                      (None, 400, 400, 32) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 200, 200, 32) 0           elu1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 200, 200, 48) 13872       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 200, 200, 48) 192         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu2 (ELU)                      (None, 200, 200, 48) 0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 100, 100, 48) 0           elu2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 100, 100, 64) 27712       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 100, 100, 64) 256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu3 (ELU)                      (None, 100, 100, 64) 0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 50, 50, 64)   0           elu3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 50, 50, 64)   36928       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 50, 50, 64)   256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu4 (ELU)                      (None, 50, 50, 64)   0           bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 25, 25, 64)   0           elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 25, 25, 48)   27696       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 25, 25, 48)   192         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu5 (ELU)                      (None, 25, 25, 48)   0           bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 12, 12, 48)   0           elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 12, 12, 48)   20784       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 12, 12, 48)   192         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu6 (ELU)                      (None, 12, 12, 48)   0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling2D)            (None, 6, 6, 48)     0           elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 6, 6, 32)     13856       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn7 (BatchNormalization)        (None, 6, 6, 32)     128         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu7 (ELU)                      (None, 6, 6, 32)     0           bn7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "classes4 (Conv2D)               (None, 50, 50, 8)    4616        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes5 (Conv2D)               (None, 25, 25, 8)    3464        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes6 (Conv2D)               (None, 12, 12, 8)    3464        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes7 (Conv2D)               (None, 6, 6, 8)      2312        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes4 (Conv2D)                 (None, 50, 50, 16)   9232        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes5 (Conv2D)                 (None, 25, 25, 16)   6928        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes6 (Conv2D)                 (None, 12, 12, 16)   6928        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes7 (Conv2D)                 (None, 6, 6, 16)     4624        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes4_reshape (Reshape)      (None, 10000, 2)     0           classes4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes5_reshape (Reshape)      (None, 2500, 2)      0           classes5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes6_reshape (Reshape)      (None, 576, 2)       0           classes6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes7_reshape (Reshape)      (None, 144, 2)       0           classes7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors4 (AnchorBoxes)          (None, 50, 50, 4, 8) 0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors5 (AnchorBoxes)          (None, 25, 25, 4, 8) 0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors6 (AnchorBoxes)          (None, 12, 12, 4, 8) 0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors7 (AnchorBoxes)          (None, 6, 6, 4, 8)   0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classes_concat (Concatenate)    (None, 13220, 2)     0           classes4_reshape[0][0]           \n",
      "                                                                 classes5_reshape[0][0]           \n",
      "                                                                 classes6_reshape[0][0]           \n",
      "                                                                 classes7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "boxes4_reshape (Reshape)        (None, 10000, 4)     0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes5_reshape (Reshape)        (None, 2500, 4)      0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes6_reshape (Reshape)        (None, 576, 4)       0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes7_reshape (Reshape)        (None, 144, 4)       0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4_reshape (Reshape)      (None, 10000, 8)     0           anchors4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors5_reshape (Reshape)      (None, 2500, 8)      0           anchors5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors6_reshape (Reshape)      (None, 576, 8)       0           anchors6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors7_reshape (Reshape)      (None, 144, 8)       0           anchors7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes_softmax (Activation)    (None, 13220, 2)     0           classes_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes_concat (Concatenate)      (None, 13220, 4)     0           boxes4_reshape[0][0]             \n",
      "                                                                 boxes5_reshape[0][0]             \n",
      "                                                                 boxes6_reshape[0][0]             \n",
      "                                                                 boxes7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "anchors_concat (Concatenate)    (None, 13220, 8)     0           anchors4_reshape[0][0]           \n",
      "                                                                 anchors5_reshape[0][0]           \n",
      "                                                                 anchors6_reshape[0][0]           \n",
      "                                                                 anchors7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 13220, 14)    0           classes_softmax[0][0]            \n",
      "                                                                 boxes_concat[0][0]               \n",
      "                                                                 anchors_concat[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 186,192\n",
      "Trainable params: 185,520\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import sys\n",
    "sys.path += [os.path.abspath('../ssd_keras-master')]\n",
    "\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
    "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
    "\n",
    "\n",
    "def makedirs(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 100:\n",
    "        return 0.001\n",
    "    elif epoch < 150:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "config_path = 'config_7_fault_1.json'\n",
    "\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "###############################\n",
    "#   Parse the annotations\n",
    "###############################\n",
    "path_imgs_training = config['train']['train_image_folder']\n",
    "path_anns_training = config['train']['train_annot_folder']\n",
    "path_imgs_val =  config['test']['test_image_folder']\n",
    "path_anns_val = config['test']['test_annot_folder']\n",
    "labels = config['model']['labels']\n",
    "categories = {}\n",
    "#categories = {\"Razor\": 1, \"Gun\": 2, \"Knife\": 3, \"Shuriken\": 4} #la categor√≠a 0 es la background\n",
    "for i in range(len(labels)): categories[labels[i]] = i+1\n",
    "print('\\nTraining on: \\t' + str(categories) + '\\n')\n",
    "\n",
    "####################################\n",
    "#   Parameters\n",
    "###################################\n",
    "    #%%\n",
    "img_height = config['model']['input'] # Height of the model input images\n",
    "img_width = config['model']['input'] # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = len(labels) # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.01, 0.05, 0.1, 0.2, 0.37, 0.54, 0.71] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "#scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_pascal #[0.01, 0.05, 0.1, 0.2 ,0.3, 0.37, 0.54]\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "\n",
    "model_path = config['train']['saved_weights_name']\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"\\nLoading pretrained weights.\\n\")\n",
    "    # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "    model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                           'L2Normalization': L2Normalization,\n",
    "                                           'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "else:\n",
    "    ####################################\n",
    "    #   Build the Keras model.\n",
    "    ###################################\n",
    "\n",
    "    if config['model']['backend'] == 'ssd300':\n",
    "        #weights_path = 'VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.h5'\n",
    "        from models.keras_ssd300 import ssd_300 as ssd\n",
    "\n",
    "        model = ssd(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "\n",
    "    elif config['model']['backend'] == 'ssd7':\n",
    "        #weights_path = 'VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "        from models.keras_ssd7 import build_model as ssd\n",
    "        scales = [0.01, 0.08, 0.16, 0.32, 0.64] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "        aspect_ratios = [0.5 ,1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "        two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "        steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "        offsets = None\n",
    "        model = ssd(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_global=aspect_ratios,\n",
    "                aspect_ratios_per_layer=None,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=None,\n",
    "                divide_by_stddev=None)\n",
    "\n",
    "    else :\n",
    "        print('Wrong Backend')\n",
    "\n",
    "\n",
    "\n",
    "    print('OK create model')\n",
    "     #sgd = SGD(lr=config['train']['learning_rate'], momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "    # TODO: Set the path to the weights you want to load. only for ssd300 or ssd512\n",
    "\n",
    "    weights_path = '../ssd_keras-master/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "    print(\"\\nLoading pretrained weights VGG.\\n\")\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "    #    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "    #    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "\n",
    "    #adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    optimizer = Adam(lr=config['train']['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=optimizer, loss=ssd_loss.compute_loss)\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciar los generadores de datos y entrenamiento del modelo.\n",
    "\n",
    "*Cambio realizado para leer png y jpg. keras-ssd-master/data_generator/object_detection_2d_data_generator.py funci√≥n parse_xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:00<00:00, 110.18it/s]\n",
      "Processing image set 'test.txt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 68.64it/s]\n",
      "1 : 444\n",
      "Number of images in the training dataset:\t    33\n",
      "Number of images in the validation dataset:\t     2\n",
      "WARNING:tensorflow:From /home/dl-desktop/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 10.6549 - val_loss: 7.1380\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.13801, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 7.9023 - val_loss: 8.1389\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.13801\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 6.9971 - val_loss: 6.5428\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.13801 to 6.54282, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 6.9129 - val_loss: 5.2096\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.54282 to 5.20957, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 6.6221 - val_loss: 5.7554\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 5.20957\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 6.2810 - val_loss: 7.4999\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 5.20957\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 6.2034 - val_loss: 8.1129\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.20957\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 5.8430 - val_loss: 5.0259\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.20957 to 5.02593, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 5.8222 - val_loss: 4.7504\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.02593 to 4.75040, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 5.7965 - val_loss: 5.2418\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.75040\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 5.7147 - val_loss: 5.0379\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.75040\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 6.0124 - val_loss: 6.9272\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.75040\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 5.8754 - val_loss: 6.6574\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.75040\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 5.9797 - val_loss: 4.7180\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.75040 to 4.71805, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 5.4824 - val_loss: 4.7904\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.71805\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 5.8061 - val_loss: 6.7183\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.71805\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 5.8219 - val_loss: 5.2346\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.71805\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 5.3119 - val_loss: 4.6287\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.71805 to 4.62874, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 5.5968 - val_loss: 7.2247\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.62874\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 5.1902 - val_loss: 4.9278\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.62874\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 5.4595 - val_loss: 4.8812\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.62874\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 5.3020 - val_loss: 5.8746\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.62874\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 5.1747 - val_loss: 6.2522\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.62874\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 5.2842 - val_loss: 7.1665\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.62874\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 5.2352 - val_loss: 6.2755\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.62874\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 5.3286 - val_loss: 6.8056\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.62874\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 5.1623 - val_loss: 5.1693\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.62874\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 5.1827 - val_loss: 6.2402\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.62874\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 5.0811 - val_loss: 5.0592\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.62874\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.9780 - val_loss: 4.0382\n",
      "\n",
      "Epoch 00030: val_loss improved from 4.62874 to 4.03825, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 5.0581 - val_loss: 5.0438\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.03825\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 5.5756 - val_loss: 4.3488\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.03825\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 229ms/step - loss: 5.1219 - val_loss: 4.1021\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4.03825\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 5.2336 - val_loss: 6.5314\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.03825\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 5.0825 - val_loss: 5.4485\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4.03825\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.9638 - val_loss: 4.1527\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4.03825\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 5.0223 - val_loss: 4.2804\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4.03825\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 4.9524 - val_loss: 4.6403\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4.03825\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.8690 - val_loss: 5.0897\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4.03825\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 4.9967 - val_loss: 6.5734\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4.03825\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.6935 - val_loss: 4.8306\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4.03825\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.9150 - val_loss: 5.5249\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4.03825\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.9159 - val_loss: 4.5594\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4.03825\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.9590 - val_loss: 5.4138\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4.03825\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.9129 - val_loss: 5.2372\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4.03825\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 4.9230 - val_loss: 4.2868\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4.03825\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.7760 - val_loss: 3.9728\n",
      "\n",
      "Epoch 00047: val_loss improved from 4.03825 to 3.97277, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.7739 - val_loss: 4.5149\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.97277\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.8919 - val_loss: 4.3892\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.97277\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.5565 - val_loss: 4.6482\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.97277\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.4726 - val_loss: 4.4884\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.97277\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.8452 - val_loss: 5.0178\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.97277\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.6518 - val_loss: 4.1244\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.97277\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 5.0259 - val_loss: 5.0076\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.97277\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 4.8086 - val_loss: 4.0930\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.97277\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.5952 - val_loss: 5.0663\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.97277\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 4.7587 - val_loss: 4.4776\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.97277\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.6116 - val_loss: 3.9222\n",
      "\n",
      "Epoch 00058: val_loss improved from 3.97277 to 3.92225, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.6267 - val_loss: 4.5797\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.92225\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.7478 - val_loss: 3.8782\n",
      "\n",
      "Epoch 00060: val_loss improved from 3.92225 to 3.87817, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.5312 - val_loss: 4.4061\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.87817\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.4557 - val_loss: 3.9146\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.87817\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.6314 - val_loss: 4.5734\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.87817\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.5498 - val_loss: 5.9857\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.87817\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.5426 - val_loss: 6.1037\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.87817\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.7414 - val_loss: 4.6923\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.87817\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 4.5896 - val_loss: 3.7859\n",
      "\n",
      "Epoch 00067: val_loss improved from 3.87817 to 3.78585, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.6831 - val_loss: 3.9670\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.78585\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 231ms/step - loss: 4.8604 - val_loss: 5.3849\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.78585\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.5709 - val_loss: 4.4797\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.78585\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 4.4958 - val_loss: 4.6507\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.78585\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 4.4013 - val_loss: 4.1583\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.78585\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.4782 - val_loss: 3.9448\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.78585\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 4.5436 - val_loss: 4.9104\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.78585\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.4747 - val_loss: 5.1044\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.78585\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.4400 - val_loss: 3.9510\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.78585\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.8100 - val_loss: 3.7751\n",
      "\n",
      "Epoch 00077: val_loss improved from 3.78585 to 3.77514, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.3564 - val_loss: 5.0605\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.77514\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 4.4826 - val_loss: 4.5409\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.77514\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 4.4823 - val_loss: 4.0823\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.77514\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 4.3587 - val_loss: 4.4663\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.77514\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.4684 - val_loss: 3.8928\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.77514\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 4.5686 - val_loss: 3.7042\n",
      "\n",
      "Epoch 00083: val_loss improved from 3.77514 to 3.70417, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 4.5652 - val_loss: 6.2923\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.70417\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.4278 - val_loss: 4.2425\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.70417\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.5282 - val_loss: 4.0433\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.70417\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.3153 - val_loss: 4.0100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.70417\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.3400 - val_loss: 3.8899\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.70417\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.2937 - val_loss: 4.2786\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.70417\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 4.4161 - val_loss: 3.8800\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.70417\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 4.3962 - val_loss: 3.9083\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.70417\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 4.1707 - val_loss: 3.7263\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.70417\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.0858 - val_loss: 3.7792\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.70417\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 4.3901 - val_loss: 5.2404\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.70417\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.2682 - val_loss: 3.7054\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.70417\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.4278 - val_loss: 5.4239\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.70417\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.3972 - val_loss: 3.6471\n",
      "\n",
      "Epoch 00097: val_loss improved from 3.70417 to 3.64705, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 4.1795 - val_loss: 3.6605\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.64705\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 4.2485 - val_loss: 3.6667\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.64705\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.1815 - val_loss: 3.8390\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.64705\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 4.0925 - val_loss: 3.5656\n",
      "\n",
      "Epoch 00101: val_loss improved from 3.64705 to 3.56559, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 4.0260 - val_loss: 3.5725\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 3.56559\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.0330 - val_loss: 3.5701\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3.56559\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 4.0368 - val_loss: 3.5767\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3.56559\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 24s 239ms/step - loss: 4.0011 - val_loss: 3.5793\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3.56559\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 3.9883 - val_loss: 3.5621\n",
      "\n",
      "Epoch 00106: val_loss improved from 3.56559 to 3.56213, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 4.0447 - val_loss: 3.6073\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.56213\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 4.0080 - val_loss: 3.4952\n",
      "\n",
      "Epoch 00108: val_loss improved from 3.56213 to 3.49518, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 3.9847 - val_loss: 3.6319\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.49518\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 3.9790 - val_loss: 3.5412\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3.49518\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 3.9774 - val_loss: 3.5972\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.49518\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 3.9309 - val_loss: 3.4730\n",
      "\n",
      "Epoch 00112: val_loss improved from 3.49518 to 3.47297, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 3.9758 - val_loss: 3.4766\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3.47297\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 3.9842 - val_loss: 3.5218\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.47297\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 3.9845 - val_loss: 4.4679\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.47297\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 3.9049 - val_loss: 3.4957\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3.47297\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.8415 - val_loss: 3.6990\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3.47297\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.9522 - val_loss: 3.5176\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.47297\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.9326 - val_loss: 3.5038\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3.47297\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8707 - val_loss: 3.5074\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3.47297\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8843 - val_loss: 3.5110\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3.47297\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 4.0774 - val_loss: 3.5721\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3.47297\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8747 - val_loss: 3.5390\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3.47297\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 3.9969 - val_loss: 3.5060\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3.47297\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.9292 - val_loss: 3.4959\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3.47297\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8092 - val_loss: 3.4940\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3.47297\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.9727 - val_loss: 3.6423\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3.47297\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.9268 - val_loss: 3.5594\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3.47297\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.9828 - val_loss: 3.5784\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 3.47297\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.9173 - val_loss: 3.4558\n",
      "\n",
      "Epoch 00130: val_loss improved from 3.47297 to 3.45582, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8509 - val_loss: 3.4421\n",
      "\n",
      "Epoch 00131: val_loss improved from 3.45582 to 3.44215, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.9329 - val_loss: 3.4858\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3.44215\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8279 - val_loss: 3.4839\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3.44215\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8744 - val_loss: 3.4289\n",
      "\n",
      "Epoch 00134: val_loss improved from 3.44215 to 3.42894, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.9094 - val_loss: 3.5704\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3.42894\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 3.9023 - val_loss: 3.6963\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3.42894\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.9174 - val_loss: 3.4380\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3.42894\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.9170 - val_loss: 3.4615\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3.42894\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8904 - val_loss: 3.4831\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 3.42894\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 231ms/step - loss: 3.9020 - val_loss: 3.4521\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 3.42894\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.9449 - val_loss: 3.4298\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 3.42894\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.9587 - val_loss: 3.5832\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 3.42894\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8442 - val_loss: 3.4396\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 3.42894\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7764 - val_loss: 3.5899\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 3.42894\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8358 - val_loss: 3.6356\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 3.42894\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8529 - val_loss: 3.5144\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 3.42894\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8630 - val_loss: 3.5363\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 3.42894\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8609 - val_loss: 3.5237\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 3.42894\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.8884 - val_loss: 3.3907\n",
      "\n",
      "Epoch 00149: val_loss improved from 3.42894 to 3.39067, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8277 - val_loss: 3.5137\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 3.39067\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7854 - val_loss: 3.4483\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 3.39067\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.7544 - val_loss: 3.4099\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 3.39067\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8393 - val_loss: 3.3969\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 3.39067\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.8679 - val_loss: 3.4144\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 3.39067\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8372 - val_loss: 3.4349\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 3.39067\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8084 - val_loss: 3.4527\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 3.39067\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.9643 - val_loss: 3.4152\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 3.39067\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8958 - val_loss: 3.4274\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 3.39067\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7517 - val_loss: 3.4122\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 3.39067\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8706 - val_loss: 3.4046\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 3.39067\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8000 - val_loss: 3.4109\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 3.39067\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7853 - val_loss: 3.4250\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 3.39067\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8154 - val_loss: 3.4399\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 3.39067\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8560 - val_loss: 3.4332\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 3.39067\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7278 - val_loss: 3.4132\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 3.39067\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7803 - val_loss: 3.3863\n",
      "\n",
      "Epoch 00166: val_loss improved from 3.39067 to 3.38626, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.8497 - val_loss: 3.4022\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 3.38626\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.8377 - val_loss: 3.4278\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 3.38626\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8392 - val_loss: 3.4152\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 3.38626\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7774 - val_loss: 3.3980\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 3.38626\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8115 - val_loss: 3.4006\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3.38626\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.9257 - val_loss: 3.4249\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 3.38626\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7990 - val_loss: 3.4052\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 3.38626\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8021 - val_loss: 3.4211\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 3.38626\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8549 - val_loss: 3.4450\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 3.38626\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 234ms/step - loss: 3.8271 - val_loss: 3.3880\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 3.38626\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7684 - val_loss: 3.3919\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 3.38626\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7729 - val_loss: 3.4049\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 3.38626\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8642 - val_loss: 3.4236\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 3.38626\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8538 - val_loss: 3.4058\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 3.38626\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7679 - val_loss: 3.4263\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 3.38626\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7583 - val_loss: 3.4005\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 3.38626\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.8434 - val_loss: 3.3924\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 3.38626\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7685 - val_loss: 3.4177\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 3.38626\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8087 - val_loss: 3.3950\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 3.38626\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.7872 - val_loss: 3.4330\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 3.38626\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7791 - val_loss: 3.4135\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 3.38626\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8809 - val_loss: 3.4036\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 3.38626\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8102 - val_loss: 3.3998\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 3.38626\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7757 - val_loss: 3.3909\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 3.38626\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.7651 - val_loss: 3.4117\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3.38626\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8146 - val_loss: 3.4259\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 3.38626\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8433 - val_loss: 3.4080\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 3.38626\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8861 - val_loss: 3.4040\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 3.38626\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7946 - val_loss: 3.4245\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 3.38626\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.8797 - val_loss: 3.4409\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 3.38626\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7990 - val_loss: 3.3932\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 3.38626\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8696 - val_loss: 3.3906\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 3.38626\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.7860 - val_loss: 3.4140\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 3.38626\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.7718 - val_loss: 3.4198\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 3.38626\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7662 - val_loss: 3.4044\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 3.38626\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7226 - val_loss: 3.3981\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 3.38626\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8132 - val_loss: 3.4034\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 3.38626\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8098 - val_loss: 3.4484\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 3.38626\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8758 - val_loss: 3.4032\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 3.38626\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8907 - val_loss: 3.4192\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 3.38626\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.9101 - val_loss: 3.3906\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 3.38626\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8165 - val_loss: 3.4298\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 3.38626\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 3.8523 - val_loss: 3.3792\n",
      "\n",
      "Epoch 00209: val_loss improved from 3.38626 to 3.37916, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8496 - val_loss: 3.3872\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 3.37916\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7777 - val_loss: 3.3874\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 3.37916\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 234ms/step - loss: 3.7629 - val_loss: 3.3957\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 3.37916\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8097 - val_loss: 3.3919\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 3.37916\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8068 - val_loss: 3.4060\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 3.37916\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7517 - val_loss: 3.4154\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 3.37916\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 3.7739 - val_loss: 3.4419\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 3.37916\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8603 - val_loss: 3.4097\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 3.37916\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8465 - val_loss: 3.4165\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 3.37916\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8130 - val_loss: 3.4307\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 3.37916\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8353 - val_loss: 3.4286\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 3.37916\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.7896 - val_loss: 3.3915\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 3.37916\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.7998 - val_loss: 3.3835\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 3.37916\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8375 - val_loss: 3.3960\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 3.37916\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7733 - val_loss: 3.4285\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 3.37916\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8395 - val_loss: 3.3897\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 3.37916\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 3.7564 - val_loss: 3.3955\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 3.37916\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7657 - val_loss: 3.4127\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 3.37916\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8107 - val_loss: 3.4006\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 3.37916\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.8435 - val_loss: 3.3819\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 3.37916\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.7888 - val_loss: 3.3923\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 3.37916\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.7604 - val_loss: 3.3797\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 3.37916\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7711 - val_loss: 3.4117\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 3.37916\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.9035 - val_loss: 3.3950\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 3.37916\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7080 - val_loss: 3.3883\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 3.37916\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.7244 - val_loss: 3.3910\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 3.37916\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7635 - val_loss: 3.3841\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 3.37916\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8134 - val_loss: 3.3761\n",
      "\n",
      "Epoch 00237: val_loss improved from 3.37916 to 3.37612, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8370 - val_loss: 3.3885\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 3.37612\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 3.8334 - val_loss: 3.4031\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 3.37612\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7503 - val_loss: 3.3764\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 3.37612\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.8170 - val_loss: 3.4142\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 3.37612\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.8331 - val_loss: 3.3930\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 3.37612\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7810 - val_loss: 3.3990\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 3.37612\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7762 - val_loss: 3.3967\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 3.37612\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.7134 - val_loss: 3.3882\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 3.37612\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7542 - val_loss: 3.3917\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 3.37612\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8824 - val_loss: 3.3967\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 3.37612\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8210 - val_loss: 3.3955\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 3.37612\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7440 - val_loss: 3.3825\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 3.37612\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7831 - val_loss: 3.3681\n",
      "\n",
      "Epoch 00250: val_loss improved from 3.37612 to 3.36807, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7880 - val_loss: 3.4132\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 3.36807\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8631 - val_loss: 3.4097\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 3.36807\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8706 - val_loss: 3.4364\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 3.36807\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7304 - val_loss: 3.3731\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 3.36807\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7871 - val_loss: 3.3941\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 3.36807\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7739 - val_loss: 3.3988\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 3.36807\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7946 - val_loss: 3.3718\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 3.36807\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7762 - val_loss: 3.3714\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 3.36807\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8246 - val_loss: 3.4150\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 3.36807\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8236 - val_loss: 3.3795\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 3.36807\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 3.7450 - val_loss: 3.3996\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 3.36807\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8179 - val_loss: 3.4078\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 3.36807\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.7841 - val_loss: 3.3827\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 3.36807\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7825 - val_loss: 3.3754\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 3.36807\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8466 - val_loss: 3.3887\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 3.36807\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7828 - val_loss: 3.3693\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 3.36807\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8028 - val_loss: 3.3789\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 3.36807\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8489 - val_loss: 3.3661\n",
      "\n",
      "Epoch 00268: val_loss improved from 3.36807 to 3.36611, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.7001 - val_loss: 3.3673\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 3.36611\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.8006 - val_loss: 3.3849\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 3.36611\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 3.7827 - val_loss: 3.3762\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 3.36611\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7435 - val_loss: 3.4069\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 3.36611\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.6934 - val_loss: 3.3726\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 3.36611\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8024 - val_loss: 3.3854\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 3.36611\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.7820 - val_loss: 3.3936\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 3.36611\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.8680 - val_loss: 3.4046\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 3.36611\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7550 - val_loss: 3.3647\n",
      "\n",
      "Epoch 00277: val_loss improved from 3.36611 to 3.36472, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.8021 - val_loss: 3.3870\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 3.36472\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.8422 - val_loss: 3.3635\n",
      "\n",
      "Epoch 00279: val_loss improved from 3.36472 to 3.36354, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7865 - val_loss: 3.3686\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 3.36354\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7568 - val_loss: 3.3644\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 3.36354\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7820 - val_loss: 3.3626\n",
      "\n",
      "Epoch 00282: val_loss improved from 3.36354 to 3.36264, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 228ms/step - loss: 3.6678 - val_loss: 3.3912\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 3.36264\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7719 - val_loss: 3.3567\n",
      "\n",
      "Epoch 00284: val_loss improved from 3.36264 to 3.35674, saving model to experimento_ssd7_fault_1.h5\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 3.7915 - val_loss: 3.3633\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 3.35674\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.8256 - val_loss: 3.3701\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 3.35674\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7223 - val_loss: 3.3879\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 3.35674\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.8087 - val_loss: 3.3747\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 3.35674\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 3.8417 - val_loss: 3.3716\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 3.35674\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7632 - val_loss: 3.3679\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 3.35674\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7730 - val_loss: 3.3928\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 3.35674\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 3.7766 - val_loss: 3.3722\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 3.35674\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7631 - val_loss: 3.3627\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 3.35674\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 3.6896 - val_loss: 3.3722\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 3.35674\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7635 - val_loss: 3.3677\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 3.35674\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7644 - val_loss: 3.3910\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 3.35674\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 3.7975 - val_loss: 3.3956\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 3.35674\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 3.8009 - val_loss: 3.4185\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 3.35674\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 3.7140 - val_loss: 3.3914\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 3.35674\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 3.7595 - val_loss: 3.3685\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 3.35674\n"
     ]
    }
   ],
   "source": [
    "#ENTRENAMIENTO DE MODELO\n",
    "#####################################################################\n",
    "#  Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "######################################################################\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "\n",
    "\n",
    "\n",
    "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
    "classes = ['background' ] + labels\n",
    "\n",
    "train_dataset.parse_xml(images_dirs= [config['train']['train_image_folder']],\n",
    "                        image_set_filenames=[config['train']['train_image_set_filename']],\n",
    "                        annotations_dirs=[config['train']['train_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = classes, \n",
    "                        #include_classes= [1],\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs= [config['test']['test_image_folder']],\n",
    "                        image_set_filenames=[config['test']['test_image_set_filename']],\n",
    "                        annotations_dirs=[config['test']['test_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = classes, \n",
    "                        #include_classes=[1],\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "#########################\n",
    "# 3: Set the batch size.\n",
    "#########################\n",
    "batch_size = config['train']['batch_size'] # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "##########################\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "##########################\n",
    "# For the training generator:\n",
    "\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "######################################3\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "#########################################\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "if config['model']['backend'] == 'ssd300':\n",
    "    predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
    "    ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                        img_width=img_width,\n",
    "                                        n_classes=n_classes,\n",
    "                                        predictor_sizes=predictor_sizes,\n",
    "                                        scales=scales,\n",
    "                                        aspect_ratios_per_layer=aspect_ratios,\n",
    "                                        two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                        steps=steps,\n",
    "                                        offsets=offsets,\n",
    "                                        clip_boxes=clip_boxes,\n",
    "                                        variances=variances,\n",
    "                                        matching_type='multi',\n",
    "                                        pos_iou_threshold=0.5,\n",
    "                                        neg_iou_limit=0.5,\n",
    "                                        normalize_coords=normalize_coords)\n",
    "\n",
    "elif config['model']['backend'] == 'ssd7':\n",
    "    predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n",
    "                       model.get_layer('classes5').output_shape[1:3],\n",
    "                       model.get_layer('classes6').output_shape[1:3],\n",
    "                       model.get_layer('classes7').output_shape[1:3]]\n",
    "    ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                img_width=img_width,\n",
    "                                n_classes=n_classes,\n",
    "                                predictor_sizes=predictor_sizes,\n",
    "                                scales=scales,\n",
    "                                aspect_ratios_global=aspect_ratios,\n",
    "                                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                steps=steps,\n",
    "                                offsets=offsets,\n",
    "                                clip_boxes=clip_boxes,\n",
    "                                variances=variances,\n",
    "                                matching_type='multi',\n",
    "                                pos_iou_threshold=0.5,\n",
    "                                neg_iou_limit=0.3,\n",
    "                                normalize_coords=normalize_coords)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "data_augmentation_chain = DataAugmentationVariableInputSize(resize_height = img_height,\n",
    "                                                            resize_width = img_width,\n",
    "                                                            random_brightness=(-48, 48, 0.5),\n",
    "                                                            random_contrast=(0.5, 1.8, 0.5),\n",
    "                                                            random_saturation=(0.5, 1.8, 0.5),\n",
    "                                                            random_hue=(18, 0.5),\n",
    "                                                            random_flip=0.5,\n",
    "                                                            n_trials_max=3,\n",
    "                                                            clip_boxes=True,\n",
    "                                                            overlap_criterion='area',\n",
    "                                                            bounds_box_filter=(0.3, 1.0),\n",
    "                                                            bounds_validator=(0.5, 1.0),\n",
    "                                                            n_boxes_min=1,\n",
    "                                                            background=(0,0,0))\n",
    "#######################\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "#######################\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=  [data_augmentation_chain],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Summary instance training\n",
    "category_train_list = []\n",
    "for image_label in train_dataset.labels:\n",
    "    category_train_list += [i[0] for i in image_label]\n",
    "summary_category_training = {train_dataset.classes[i]: category_train_list.count(i) for i in list(set(category_train_list))}\n",
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))\n",
    "\n",
    "\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "# Define model callbacks.\n",
    "#########################\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath= config['train']['saved_weights_name'],\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "#model_checkpoint.best =\n",
    "\n",
    "csv_logger = CSVLogger(filename='log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan]\n",
    "\n",
    "\n",
    "\n",
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 300 #config['train']['nb_epochs']\n",
    "steps_per_epoch = 100\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size*10),\n",
    "                              initial_epoch=initial_epoch,\n",
    "                              verbose = 1 if config['train']['debug'] else 2)\n",
    "\n",
    "history_path = config['train']['saved_weights_name'].split('.')[0] + '_history'\n",
    "\n",
    "np.save(history_path, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', '1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimento_ssd7_fault_1.h5\n"
     ]
    }
   ],
   "source": [
    "#Graficar aprendizaje\n",
    "\n",
    "history_path =config['train']['saved_weights_name'].split('.')[0] + '_history'\n",
    "\n",
    "hist_load = np.load(history_path + '.npy',allow_pickle=True).item()\n",
    "\n",
    "print(hist_load.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist_load['loss'])\n",
    "plt.plot(hist_load['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.ylim((0, 10))  \n",
    "plt.show()\n",
    "\n",
    "print(config['train']['saved_weights_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:00<00:00, 114.45it/s]\n",
      "Processing image set 'test.txt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 70.49it/s]\n",
      "Number of images in the evaluation dataset: 2\n",
      "\n",
      "Producing predictions batch-wise: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.89s/it]\n",
      "Matching predictions to ground truth, class 1/1.: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<00:00, 10261.36it/s]\n",
      "Computing precisions and recalls, class 1/1\n",
      "Computing average precision, class 1/1\n",
      "400 instances of class 1 with average precision: 0.4970\n",
      "mAP using the weighted average of precisions among classes: 0.4970\n",
      "mAP: 0.4970\n",
      "1             AP    0.497\n",
      "\n",
      "              mAP   0.497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_path = 'config_7_fault_1.json'\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "    \n",
    "model_mode = 'training'\n",
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = config['train']['saved_weights_name']\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "    \n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "\n",
    "\n",
    "\n",
    "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
    "classes = ['background' ] + labels\n",
    "\n",
    "train_dataset.parse_xml(images_dirs= [config['train']['train_image_folder']],\n",
    "                        image_set_filenames=[config['train']['train_image_set_filename']],\n",
    "                        annotations_dirs=[config['train']['train_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = ['background', 'panel', 'cell'], \n",
    "                        #include_classes=classes,\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs= [config['test']['test_image_folder']],\n",
    "                        image_set_filenames=[config['test']['test_image_set_filename']],\n",
    "                        annotations_dirs=[config['test']['test_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = ['background', 'panel', 'cell'], \n",
    "                        #include_classes=classes,\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "#########################\n",
    "# 3: Set the batch size.\n",
    "#########################\n",
    "batch_size = config['train']['batch_size'] # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluator = Evaluator(model=model,\n",
    "                      n_classes=n_classes,\n",
    "                      data_generator=val_dataset,\n",
    "                      model_mode='training')\n",
    "\n",
    "results = evaluator(img_height=img_height,\n",
    "                    img_width=img_width,\n",
    "                    batch_size=4,\n",
    "                    data_generator_mode='resize',\n",
    "                    round_confidences=False,\n",
    "                    matching_iou_threshold=0.5,\n",
    "                    border_pixels='include',\n",
    "                    sorting_algorithm='quicksort',\n",
    "                    average_precision_mode='sample',\n",
    "                    num_recall_points=11,\n",
    "                    ignore_neutral_boxes=True,\n",
    "                    return_precisions=True,\n",
    "                    return_recalls=True,\n",
    "                    return_average_precisions=True,\n",
    "                    verbose=True)\n",
    "\n",
    "mean_average_precision, average_precisions, precisions, recalls = results\n",
    "total_instances = []\n",
    "precisions = []\n",
    "\n",
    "for i in range(1, len(average_precisions)):\n",
    "    \n",
    "    print('{:.0f} instances of class'.format(len(recalls[i])),\n",
    "          classes[i], 'with average precision: {:.4f}'.format(average_precisions[i]))\n",
    "    total_instances.append(len(recalls[i]))\n",
    "    precisions.append(average_precisions[i])\n",
    "\n",
    "if sum(total_instances) == 0:\n",
    "    \n",
    "    print('No test instances found.')\n",
    "\n",
    "else:\n",
    "\n",
    "    print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
    "    print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))\n",
    "\n",
    "    for i in range(1, len(average_precisions)):\n",
    "        print(\"{:<14}{:<6}{}\".format(classes[i], 'AP', round(average_precisions[i], 3)))\n",
    "    print()\n",
    "    print(\"{:<14}{:<6}{}\".format('','mAP', round(mean_average_precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceil(val_dataset_size/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar nuevamente el modelo desde los pesos.\n",
    "Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on: \t{'1': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imageio import imread\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "config_path = 'config_7_fault_1.json'\n",
    "input_path = ['fault_jpg_1/']\n",
    "output_path = 'result_ssd7_fault_1/'\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "makedirs(output_path)\n",
    "###############################\n",
    "#   Parse the annotations\n",
    "###############################\n",
    "score_threshold = 0.25\n",
    "score_threshold_iou = 0.5\n",
    "labels = config['model']['labels']\n",
    "categories = {}\n",
    "#categories = {\"Razor\": 1, \"Gun\": 2, \"Knife\": 3, \"Shuriken\": 4} #la categor√≠a 0 es la background\n",
    "for i in range(len(labels)): categories[labels[i]] = i+1\n",
    "print('\\nTraining on: \\t' + str(categories) + '\\n')\n",
    "\n",
    "img_height = config['model']['input'] # Height of the model input images\n",
    "img_width = config['model']['input'] # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "n_classes = len(labels) # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "classes = ['background'] + labels\n",
    "\n",
    "model_mode = 'training'\n",
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = config['train']['saved_weights_name']\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo Total: 0.466\n",
      "Tiempo promedio por imagen: 0.019\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for inp in input_path:\n",
    "    if os.path.isdir(inp):\n",
    "        for inp_file in os.listdir(inp):\n",
    "            image_paths += [inp + inp_file]\n",
    "    else:\n",
    "        image_paths += [inp]\n",
    "\n",
    "image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
    "times = []\n",
    "\n",
    "\n",
    "for img_path in image_paths:\n",
    "    orig_images = [] # Store the images here.\n",
    "    input_images = [] # Store resized versions of the images here.\n",
    "    #print(img_path)\n",
    "\n",
    "    # preprocess image for network\n",
    "    orig_images.append(imread(img_path))\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "    input_images.append(img)\n",
    "    input_images = np.array(input_images)\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(input_images)\n",
    "    y_pred_decoded = decode_detections(y_pred,\n",
    "                               confidence_thresh=score_threshold,\n",
    "                               iou_threshold=score_threshold_iou,\n",
    "                               top_k=200,\n",
    "                               normalize_coords=True,\n",
    "                               img_height=img_height,\n",
    "                               img_width=img_width)\n",
    "\n",
    "\n",
    "    #print(\"processing time: \", time.time() - start)\n",
    "    times.append(time.time() - start)\n",
    "    # correct for image scale\n",
    "\n",
    "    # visualize detections\n",
    "    # Set the colors for the bounding boxes\n",
    "    colors = plt.cm.brg(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(orig_images[0],cmap = 'gray')\n",
    "\n",
    "    current_axis = plt.gca()\n",
    "    #print(y_pred)\n",
    "    for box in y_pred_decoded[0]:\n",
    "        # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "\n",
    "        xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "        ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "        xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "        ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "\n",
    "        color = colors[int(box[0])]\n",
    "        label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "        current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "        current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.axis('off')\n",
    "    save_path = output_path + img_path.split('/')[-1]\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "file = open(output_path + 'time.txt','w')\n",
    "\n",
    "file.write('Tiempo promedio:' + str(np.mean(times)))\n",
    "\n",
    "file.close()\n",
    "print('Tiempo Total: {:.3f}'.format(np.sum(times)))\n",
    "print('Tiempo promedio por imagen: {:.3f}'.format(np.mean(times)))\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summary instance training\n",
    "category_train_list = []\n",
    "for image_label in train_dataset.labels:\n",
    "    category_train_list += [i[0] for i in train_dataset.labels[0]]\n",
    "summary_category_training = {train_dataset.classes[i]: category_train_list.count(i) for i in list(set(category_train_list))}\n",
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 99\n"
     ]
    }
   ],
   "source": [
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
