{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el modelo ssd7 \n",
    "(https://github.com/pierluigiferrari/ssd_keras#how-to-fine-tune-one-of-the-trained-models-on-your-own-dataset)\n",
    "\n",
    "Training del SSD7 (modelo reducido de SSD). Parámetros en config_7.json y descargar VGG_ILSVRC_16_layers_fc_reduced.h5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on: \t{'1': 1}\n",
      "\n",
      "WARNING:tensorflow:From /home/dl-desktop/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "OK create model\n",
      "\n",
      "Loading pretrained weights VGG.\n",
      "\n",
      "WARNING:tensorflow:From /home/dl-desktop/Desktop/Rentadrone/ssd_keras-master/keras_loss_function/keras_ssd_loss.py:133: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/dl-desktop/Desktop/Rentadrone/ssd_keras-master/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 400, 400, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 400, 400, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_channel_swap (Lambda)     (None, 400, 400, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 400, 400, 64) 1792        input_channel_swap[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1_2 (Conv2D)                (None, 400, 400, 64) 36928       conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 200, 200, 64) 0           conv1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 200, 200, 128 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2 (Conv2D)                (None, 200, 200, 128 147584      conv2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 100, 100, 128 0           conv2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1 (Conv2D)                (None, 100, 100, 256 295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2 (Conv2D)                (None, 100, 100, 256 590080      conv3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3 (Conv2D)                (None, 100, 100, 256 590080      conv3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 50, 50, 256)  0           conv3_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1 (Conv2D)                (None, 50, 50, 512)  1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2 (Conv2D)                (None, 50, 50, 512)  2359808     conv4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3 (Conv2D)                (None, 50, 50, 512)  2359808     conv4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 25, 25, 512)  0           conv4_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1 (Conv2D)                (None, 25, 25, 512)  2359808     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2 (Conv2D)                (None, 25, 25, 512)  2359808     conv5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3 (Conv2D)                (None, 25, 25, 512)  2359808     conv5_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 25, 25, 512)  0           conv5_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Conv2D)                    (None, 25, 25, 1024) 4719616     pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fc7 (Conv2D)                    (None, 25, 25, 1024) 1049600     fc6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1 (Conv2D)                (None, 25, 25, 256)  262400      fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv6_padding (ZeroPadding2D)   (None, 27, 27, 256)  0           conv6_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2 (Conv2D)                (None, 13, 13, 512)  1180160     conv6_padding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1 (Conv2D)                (None, 13, 13, 128)  65664       conv6_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv7_padding (ZeroPadding2D)   (None, 15, 15, 128)  0           conv7_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2 (Conv2D)                (None, 7, 7, 256)    295168      conv7_padding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1 (Conv2D)                (None, 7, 7, 128)    32896       conv7_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2 (Conv2D)                (None, 5, 5, 256)    295168      conv8_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1 (Conv2D)                (None, 5, 5, 128)    32896       conv8_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm (L2Normalization)  (None, 50, 50, 512)  512         conv4_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2 (Conv2D)                (None, 3, 3, 256)    295168      conv9_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_conf (Conv2D) (None, 50, 50, 8)    36872       conv4_3_norm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_conf (Conv2D)          (None, 25, 25, 12)   110604      fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_conf (Conv2D)      (None, 13, 13, 12)   55308       conv6_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_conf (Conv2D)      (None, 7, 7, 12)     27660       conv7_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_conf (Conv2D)      (None, 5, 5, 8)      18440       conv8_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_conf (Conv2D)      (None, 3, 3, 8)      18440       conv9_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_loc (Conv2D)  (None, 50, 50, 16)   73744       conv4_3_norm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_loc (Conv2D)           (None, 25, 25, 24)   221208      fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_loc (Conv2D)       (None, 13, 13, 24)   110616      conv6_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_loc (Conv2D)       (None, 7, 7, 24)     55320       conv7_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_loc (Conv2D)       (None, 5, 5, 16)     36880       conv8_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_loc (Conv2D)       (None, 3, 3, 16)     36880       conv9_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_conf_reshape  (None, 10000, 2)     0           conv4_3_norm_mbox_conf[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_conf_reshape (Reshape) (None, 3750, 2)      0           fc7_mbox_conf[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_conf_reshape (Resh (None, 1014, 2)      0           conv6_2_mbox_conf[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_conf_reshape (Resh (None, 294, 2)       0           conv7_2_mbox_conf[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_conf_reshape (Resh (None, 100, 2)       0           conv8_2_mbox_conf[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_conf_reshape (Resh (None, 36, 2)        0           conv9_2_mbox_conf[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_priorbox (Anc (None, 50, 50, 4, 8) 0           conv4_3_norm_mbox_loc[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_priorbox (AnchorBoxes) (None, 25, 25, 6, 8) 0           fc7_mbox_loc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_priorbox (AnchorBo (None, 13, 13, 6, 8) 0           conv6_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_priorbox (AnchorBo (None, 7, 7, 6, 8)   0           conv7_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_priorbox (AnchorBo (None, 5, 5, 4, 8)   0           conv8_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_priorbox (AnchorBo (None, 3, 3, 4, 8)   0           conv9_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 15194, 2)     0           conv4_3_norm_mbox_conf_reshape[0]\n",
      "                                                                 fc7_mbox_conf_reshape[0][0]      \n",
      "                                                                 conv6_2_mbox_conf_reshape[0][0]  \n",
      "                                                                 conv7_2_mbox_conf_reshape[0][0]  \n",
      "                                                                 conv8_2_mbox_conf_reshape[0][0]  \n",
      "                                                                 conv9_2_mbox_conf_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_loc_reshape ( (None, 10000, 4)     0           conv4_3_norm_mbox_loc[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_loc_reshape (Reshape)  (None, 3750, 4)      0           fc7_mbox_loc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_loc_reshape (Resha (None, 1014, 4)      0           conv6_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_loc_reshape (Resha (None, 294, 4)       0           conv7_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_loc_reshape (Resha (None, 100, 4)       0           conv8_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_loc_reshape (Resha (None, 36, 4)        0           conv9_2_mbox_loc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_norm_mbox_priorbox_resh (None, 10000, 8)     0           conv4_3_norm_mbox_priorbox[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "fc7_mbox_priorbox_reshape (Resh (None, 3750, 8)      0           fc7_mbox_priorbox[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_mbox_priorbox_reshape ( (None, 1014, 8)      0           conv6_2_mbox_priorbox[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_mbox_priorbox_reshape ( (None, 294, 8)       0           conv7_2_mbox_priorbox[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_mbox_priorbox_reshape ( (None, 100, 8)       0           conv8_2_mbox_priorbox[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_mbox_priorbox_reshape ( (None, 36, 8)        0           conv9_2_mbox_priorbox[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 15194, 2)     0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 15194, 4)     0           conv4_3_norm_mbox_loc_reshape[0][\n",
      "                                                                 fc7_mbox_loc_reshape[0][0]       \n",
      "                                                                 conv6_2_mbox_loc_reshape[0][0]   \n",
      "                                                                 conv7_2_mbox_loc_reshape[0][0]   \n",
      "                                                                 conv8_2_mbox_loc_reshape[0][0]   \n",
      "                                                                 conv9_2_mbox_loc_reshape[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 15194, 8)     0           conv4_3_norm_mbox_priorbox_reshap\n",
      "                                                                 fc7_mbox_priorbox_reshape[0][0]  \n",
      "                                                                 conv6_2_mbox_priorbox_reshape[0][\n",
      "                                                                 conv7_2_mbox_priorbox_reshape[0][\n",
      "                                                                 conv8_2_mbox_priorbox_reshape[0][\n",
      "                                                                 conv9_2_mbox_priorbox_reshape[0][\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 15194, 14)    0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,745,908\n",
      "Trainable params: 23,745,908\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import sys\n",
    "sys.path += [os.path.abspath('../../ssd_keras-master')]\n",
    "\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
    "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
    "\n",
    "\n",
    "def makedirs(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 80:\n",
    "        return 0.001\n",
    "    elif epoch < 100:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "config_path = 'config_300_fault_1.json'\n",
    "\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "###############################\n",
    "#   Parse the annotations\n",
    "###############################\n",
    "path_imgs_training = config['train']['train_image_folder']\n",
    "path_anns_training = config['train']['train_annot_folder']\n",
    "path_imgs_val =  config['test']['test_image_folder']\n",
    "path_anns_val = config['test']['test_annot_folder']\n",
    "labels = config['model']['labels']\n",
    "categories = {}\n",
    "#categories = {\"Razor\": 1, \"Gun\": 2, \"Knife\": 3, \"Shuriken\": 4} #la categoría 0 es la background\n",
    "for i in range(len(labels)): categories[labels[i]] = i+1\n",
    "print('\\nTraining on: \\t' + str(categories) + '\\n')\n",
    "\n",
    "####################################\n",
    "#   Parameters\n",
    "###################################\n",
    "    #%%\n",
    "img_height = config['model']['input'] # Height of the model input images\n",
    "img_width = config['model']['input'] # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = len(labels) # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.01, 0.05, 0.1, 0.2, 0.37, 0.54, 0.71] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "#scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_pascal\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "\n",
    "model_path = config['train']['saved_weights_name']\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "\n",
    "if config['model']['backend'] == 'ssd7':\n",
    "    #weights_path = 'VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "    scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "    aspect_ratios = [0.5 ,1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "    two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "    steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "    offsets = None\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"\\nLoading pretrained weights.\\n\")\n",
    "    # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "    model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                           'L2Normalization': L2Normalization,\n",
    "                                           'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "else:\n",
    "    ####################################\n",
    "    #   Build the Keras model.\n",
    "    ###################################\n",
    "\n",
    "    if config['model']['backend'] == 'ssd300':\n",
    "        #weights_path = 'VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.h5'\n",
    "        from models.keras_ssd300 import ssd_300 as ssd\n",
    "\n",
    "        model = ssd(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "\n",
    "    elif config['model']['backend'] == 'ssd7':\n",
    "        #weights_path = 'VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "        from models.keras_ssd7 import build_model as ssd\n",
    "        scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "        aspect_ratios = [0.5 ,1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "        two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "        steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "        offsets = None\n",
    "        model = ssd(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_global=aspect_ratios,\n",
    "                aspect_ratios_per_layer=None,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=None,\n",
    "                divide_by_stddev=None)\n",
    "\n",
    "    else :\n",
    "        print('Wrong Backend')\n",
    "\n",
    "\n",
    "\n",
    "    print('OK create model')\n",
    "     #sgd = SGD(lr=config['train']['learning_rate'], momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "    # TODO: Set the path to the weights you want to load. only for ssd300 or ssd512\n",
    "\n",
    "    weights_path = '../ssd_keras-master/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "    print(\"\\nLoading pretrained weights VGG.\\n\")\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "    #    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "    #    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "\n",
    "    #adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    optimizer = Adam(lr=config['train']['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=optimizer, loss=ssd_loss.compute_loss)\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciar los generadores de datos y entrenamiento del modelo.\n",
    "\n",
    "*Cambio realizado para leer png y jpg. keras-ssd-master/data_generator/object_detection_2d_data_generator.py función parse_xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|██████████| 33/33 [00:00<00:00, 88.77it/s]\n",
      "Processing image set 'test.txt': 100%|██████████| 2/2 [00:00<00:00, 61.92it/s]\n",
      "1 : 444\n",
      "Number of images in the training dataset:\t    33\n",
      "Number of images in the validation dataset:\t     2\n",
      "WARNING:tensorflow:From /home/dl-desktop/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/500\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 16.3709 - val_loss: 7.3757\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.37568, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 8.3424 - val_loss: 5.9648\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.37568 to 5.96482, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 81s 814ms/step - loss: 6.9268 - val_loss: 5.5916\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.96482 to 5.59162, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 81s 806ms/step - loss: 6.5707 - val_loss: 5.6131\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.59162\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 6.2085 - val_loss: 5.8056\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 5.59162\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 5.9796 - val_loss: 5.4107\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.59162 to 5.41071, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 82s 817ms/step - loss: 5.8464 - val_loss: 5.4046\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.41071 to 5.40461, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 82s 821ms/step - loss: 5.8391 - val_loss: 5.1717\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.40461 to 5.17174, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 5.6631 - val_loss: 5.1447\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.17174 to 5.14472, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 5.6221 - val_loss: 5.3356\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.14472\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 5.5115 - val_loss: 5.6827\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 5.14472\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 5.4163 - val_loss: 5.0174\n",
      "\n",
      "Epoch 00012: val_loss improved from 5.14472 to 5.01743, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 5.2737 - val_loss: 4.8928\n",
      "\n",
      "Epoch 00013: val_loss improved from 5.01743 to 4.89279, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 5.1896 - val_loss: 4.6932\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.89279 to 4.69325, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 5.0712 - val_loss: 4.7150\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.69325\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 5.0187 - val_loss: 4.7564\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.69325\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 4.9779 - val_loss: 4.6682\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.69325 to 4.66824, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 18/500\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 804ms/step - loss: 5.0324 - val_loss: 4.3389\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.66824 to 4.33889, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 19/500\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 4.8554 - val_loss: 4.3513\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.33889\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 4.7299 - val_loss: 4.2093\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.33889 to 4.20925, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 4.7058 - val_loss: 4.3614\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.20925\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 4.6238 - val_loss: 4.1315\n",
      "\n",
      "Epoch 00022: val_loss improved from 4.20925 to 4.13152, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 4.5439 - val_loss: 4.0052\n",
      "\n",
      "Epoch 00023: val_loss improved from 4.13152 to 4.00518, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 4.4489 - val_loss: 4.1691\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.00518\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 4.2741 - val_loss: 4.1397\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.00518\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 4.2250 - val_loss: 3.9073\n",
      "\n",
      "Epoch 00026: val_loss improved from 4.00518 to 3.90726, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 27/500\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 4.1448 - val_loss: 4.9886\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.90726\n",
      "Epoch 28/500\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 4.0781 - val_loss: 3.9171\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.90726\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 4.0313 - val_loss: 3.8165\n",
      "\n",
      "Epoch 00029: val_loss improved from 3.90726 to 3.81654, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.8771 - val_loss: 3.8606\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.81654\n",
      "Epoch 31/500\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 801ms/step - loss: 3.7454 - val_loss: 3.9101\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.81654\n",
      "Epoch 32/500\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.7843 - val_loss: 3.7655\n",
      "\n",
      "Epoch 00032: val_loss improved from 3.81654 to 3.76554, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 33/500\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.6930 - val_loss: 3.7563\n",
      "\n",
      "Epoch 00033: val_loss improved from 3.76554 to 3.75635, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.7410 - val_loss: 3.6279\n",
      "\n",
      "Epoch 00034: val_loss improved from 3.75635 to 3.62786, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.6264 - val_loss: 3.6042\n",
      "\n",
      "Epoch 00035: val_loss improved from 3.62786 to 3.60423, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 36/500\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.7013 - val_loss: 3.6819\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.60423\n",
      "Epoch 37/500\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.7254 - val_loss: 3.8854\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.60423\n",
      "Epoch 38/500\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.7286 - val_loss: 3.7263\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.60423\n",
      "Epoch 39/500\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.6215 - val_loss: 3.7384\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.60423\n",
      "Epoch 40/500\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.5454 - val_loss: 3.6938\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.60423\n",
      "Epoch 41/500\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.5633 - val_loss: 3.8448\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.60423\n",
      "Epoch 42/500\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 3.5717 - val_loss: 3.7542\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.60423\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.4769 - val_loss: 3.5321\n",
      "\n",
      "Epoch 00043: val_loss improved from 3.60423 to 3.53213, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.5226 - val_loss: 3.7346\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.53213\n",
      "Epoch 45/500\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.4415 - val_loss: 3.6502\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.53213\n",
      "Epoch 46/500\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 3.4931 - val_loss: 3.6032\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.53213\n",
      "Epoch 47/500\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.4958 - val_loss: 3.6229\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.53213\n",
      "Epoch 48/500\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.4587 - val_loss: 3.6163\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.53213\n",
      "Epoch 49/500\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.4677 - val_loss: 3.7527\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.53213\n",
      "Epoch 50/500\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.4107 - val_loss: 3.5594\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.53213\n",
      "Epoch 51/500\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.4377 - val_loss: 3.5592\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.53213\n",
      "Epoch 52/500\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 803ms/step - loss: 3.3956 - val_loss: 3.7218\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.53213\n",
      "Epoch 53/500\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.4251 - val_loss: 3.5406\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.53213\n",
      "Epoch 54/500\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3444 - val_loss: 3.7238\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.53213\n",
      "Epoch 55/500\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3245 - val_loss: 3.9998\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.53213\n",
      "Epoch 56/500\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.3507 - val_loss: 3.7415\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.53213\n",
      "Epoch 57/500\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3039 - val_loss: 3.5360\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.53213\n",
      "Epoch 58/500\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3545 - val_loss: 3.6459\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.53213\n",
      "Epoch 59/500\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.5069 - val_loss: 3.5454\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.53213\n",
      "Epoch 60/500\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3454 - val_loss: 3.5025\n",
      "\n",
      "Epoch 00060: val_loss improved from 3.53213 to 3.50248, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 61/500\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.3401 - val_loss: 3.4923\n",
      "\n",
      "Epoch 00061: val_loss improved from 3.50248 to 3.49233, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 62/500\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.2500 - val_loss: 3.3722\n",
      "\n",
      "Epoch 00062: val_loss improved from 3.49233 to 3.37216, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 63/500\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.2749 - val_loss: 3.5324\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.37216\n",
      "Epoch 64/500\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.2514 - val_loss: 3.3746\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.37216\n",
      "Epoch 65/500\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.1946 - val_loss: 3.0985\n",
      "\n",
      "Epoch 00065: val_loss improved from 3.37216 to 3.09848, saving model to experimento_ssd300_fault_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.2282 - val_loss: 3.2196\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.09848\n",
      "Epoch 67/500\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.1572 - val_loss: 3.2833\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.09848\n",
      "Epoch 68/500\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.1747 - val_loss: 3.3269\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.09848\n",
      "Epoch 69/500\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.2022 - val_loss: 3.5159\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.09848\n",
      "Epoch 70/500\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.2015 - val_loss: 3.0329\n",
      "\n",
      "Epoch 00070: val_loss improved from 3.09848 to 3.03288, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 71/500\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.1563 - val_loss: 3.1785\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.03288\n",
      "Epoch 72/500\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.0944 - val_loss: 3.3246\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.03288\n",
      "Epoch 73/500\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.0834 - val_loss: 3.3990\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.03288\n",
      "Epoch 74/500\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.0638 - val_loss: 3.2314\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.03288\n",
      "Epoch 75/500\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.0576 - val_loss: 3.2828\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.03288\n",
      "Epoch 76/500\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 3.1641 - val_loss: 3.1036\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.03288\n",
      "Epoch 77/500\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.0128 - val_loss: 3.3556\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.03288\n",
      "Epoch 78/500\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.0574 - val_loss: 3.1095\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.03288\n",
      "Epoch 79/500\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 3.0328 - val_loss: 3.1693\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.03288\n",
      "Epoch 80/500\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 3.0884 - val_loss: 2.9858\n",
      "\n",
      "Epoch 00080: val_loss improved from 3.03288 to 2.98575, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 81/500\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.8945 - val_loss: 3.1375\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.98575\n",
      "Epoch 82/500\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.8242 - val_loss: 3.1283\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.98575\n",
      "Epoch 83/500\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.8158 - val_loss: 3.0812\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.98575\n",
      "Epoch 84/500\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.7252 - val_loss: 3.0028\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.98575\n",
      "Epoch 85/500\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.7557 - val_loss: 3.0320\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.98575\n",
      "Epoch 86/500\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.6858 - val_loss: 3.0034\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.98575\n",
      "Epoch 87/500\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.6145 - val_loss: 3.0041\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.98575\n",
      "Epoch 88/500\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.6769 - val_loss: 3.0108\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.98575\n",
      "Epoch 89/500\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.6359 - val_loss: 2.9382\n",
      "\n",
      "Epoch 00089: val_loss improved from 2.98575 to 2.93818, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 90/500\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.5922 - val_loss: 2.9442\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.93818\n",
      "Epoch 91/500\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.6036 - val_loss: 2.9341\n",
      "\n",
      "Epoch 00091: val_loss improved from 2.93818 to 2.93406, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 92/500\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.5844 - val_loss: 2.9017\n",
      "\n",
      "Epoch 00092: val_loss improved from 2.93406 to 2.90171, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 93/500\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.5528 - val_loss: 2.8696\n",
      "\n",
      "Epoch 00093: val_loss improved from 2.90171 to 2.86965, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 94/500\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.5428 - val_loss: 2.9039\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.86965\n",
      "Epoch 95/500\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.5477 - val_loss: 2.8995\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.86965\n",
      "Epoch 96/500\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.5020 - val_loss: 2.9773\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.86965\n",
      "Epoch 97/500\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.5610 - val_loss: 2.8112\n",
      "\n",
      "Epoch 00097: val_loss improved from 2.86965 to 2.81115, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 98/500\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4317 - val_loss: 2.8764\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.81115\n",
      "Epoch 99/500\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.5008 - val_loss: 2.8408\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.81115\n",
      "Epoch 100/500\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0001.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4662 - val_loss: 2.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_loss did not improve from 2.81115\n",
      "Epoch 101/500\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.4243 - val_loss: 2.7867\n",
      "\n",
      "Epoch 00101: val_loss improved from 2.81115 to 2.78665, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 102/500\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4661 - val_loss: 2.7834\n",
      "\n",
      "Epoch 00102: val_loss improved from 2.78665 to 2.78338, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 103/500\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4118 - val_loss: 2.7545\n",
      "\n",
      "Epoch 00103: val_loss improved from 2.78338 to 2.75448, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 104/500\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4510 - val_loss: 2.7466\n",
      "\n",
      "Epoch 00104: val_loss improved from 2.75448 to 2.74665, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 105/500\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4811 - val_loss: 2.7390\n",
      "\n",
      "Epoch 00105: val_loss improved from 2.74665 to 2.73900, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 106/500\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4332 - val_loss: 2.7359\n",
      "\n",
      "Epoch 00106: val_loss improved from 2.73900 to 2.73586, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 107/500\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.4275 - val_loss: 2.7517\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.73586\n",
      "Epoch 108/500\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3691 - val_loss: 2.7352\n",
      "\n",
      "Epoch 00108: val_loss improved from 2.73586 to 2.73520, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 109/500\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4060 - val_loss: 2.7100\n",
      "\n",
      "Epoch 00109: val_loss improved from 2.73520 to 2.70995, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 110/500\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.4380 - val_loss: 2.6994\n",
      "\n",
      "Epoch 00110: val_loss improved from 2.70995 to 2.69939, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 111/500\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4594 - val_loss: 2.7045\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2.69939\n",
      "Epoch 112/500\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.4270 - val_loss: 2.7049\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.69939\n",
      "Epoch 113/500\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3366 - val_loss: 2.7099\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.69939\n",
      "Epoch 114/500\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3707 - val_loss: 2.7035\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.69939\n",
      "Epoch 115/500\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4000 - val_loss: 2.7090\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.69939\n",
      "Epoch 116/500\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3661 - val_loss: 2.7183\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.69939\n",
      "Epoch 117/500\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4599 - val_loss: 2.7063\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2.69939\n",
      "Epoch 118/500\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3982 - val_loss: 2.7186\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2.69939\n",
      "Epoch 119/500\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.4185 - val_loss: 2.7158\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2.69939\n",
      "Epoch 120/500\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.4261 - val_loss: 2.7000\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2.69939\n",
      "Epoch 121/500\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3914 - val_loss: 2.7090\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2.69939\n",
      "Epoch 122/500\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4349 - val_loss: 2.6965\n",
      "\n",
      "Epoch 00122: val_loss improved from 2.69939 to 2.69654, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 123/500\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.4154 - val_loss: 2.7004\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2.69654\n",
      "Epoch 124/500\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3835 - val_loss: 2.7080\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2.69654\n",
      "Epoch 125/500\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3307 - val_loss: 2.6899\n",
      "\n",
      "Epoch 00125: val_loss improved from 2.69654 to 2.68988, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 126/500\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.3386 - val_loss: 2.6951\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2.68988\n",
      "Epoch 127/500\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.4267 - val_loss: 2.6741\n",
      "\n",
      "Epoch 00127: val_loss improved from 2.68988 to 2.67407, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 128/500\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3711 - val_loss: 2.6878\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2.67407\n",
      "Epoch 129/500\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3586 - val_loss: 2.6804\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2.67407\n",
      "Epoch 130/500\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3444 - val_loss: 2.6767\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2.67407\n",
      "Epoch 131/500\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.4412 - val_loss: 2.6694\n",
      "\n",
      "Epoch 00131: val_loss improved from 2.67407 to 2.66941, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 132/500\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3977 - val_loss: 2.6752\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2.66941\n",
      "Epoch 133/500\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3353 - val_loss: 2.6631\n",
      "\n",
      "Epoch 00133: val_loss improved from 2.66941 to 2.66305, saving model to experimento_ssd300_fault_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/500\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3689 - val_loss: 2.6725\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2.66305\n",
      "Epoch 135/500\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3339 - val_loss: 2.6928\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2.66305\n",
      "Epoch 136/500\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3850 - val_loss: 2.6774\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2.66305\n",
      "Epoch 137/500\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3342 - val_loss: 2.6772\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2.66305\n",
      "Epoch 138/500\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3865 - val_loss: 2.6818\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2.66305\n",
      "Epoch 139/500\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3988 - val_loss: 2.6868\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2.66305\n",
      "Epoch 140/500\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3424 - val_loss: 2.6794\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2.66305\n",
      "Epoch 141/500\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3614 - val_loss: 2.6603\n",
      "\n",
      "Epoch 00141: val_loss improved from 2.66305 to 2.66026, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 142/500\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3719 - val_loss: 2.6549\n",
      "\n",
      "Epoch 00142: val_loss improved from 2.66026 to 2.65490, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 143/500\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3043 - val_loss: 2.6432\n",
      "\n",
      "Epoch 00143: val_loss improved from 2.65490 to 2.64322, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 144/500\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2873 - val_loss: 2.6532\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2.64322\n",
      "Epoch 145/500\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3059 - val_loss: 2.6704\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2.64322\n",
      "Epoch 146/500\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3863 - val_loss: 2.6564\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2.64322\n",
      "Epoch 147/500\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2575 - val_loss: 2.6529\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2.64322\n",
      "Epoch 148/500\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3390 - val_loss: 2.6654\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2.64322\n",
      "Epoch 149/500\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3935 - val_loss: 2.6721\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2.64322\n",
      "Epoch 150/500\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3100 - val_loss: 2.6558\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2.64322\n",
      "Epoch 151/500\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3418 - val_loss: 2.6429\n",
      "\n",
      "Epoch 00151: val_loss improved from 2.64322 to 2.64291, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 152/500\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3659 - val_loss: 2.6681\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 2.64291\n",
      "Epoch 153/500\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3580 - val_loss: 2.6447\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 2.64291\n",
      "Epoch 154/500\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3295 - val_loss: 2.6318\n",
      "\n",
      "Epoch 00154: val_loss improved from 2.64291 to 2.63178, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 155/500\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.2901 - val_loss: 2.6443\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 2.63178\n",
      "Epoch 156/500\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3641 - val_loss: 2.6441\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 2.63178\n",
      "Epoch 157/500\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2748 - val_loss: 2.6224\n",
      "\n",
      "Epoch 00157: val_loss improved from 2.63178 to 2.62240, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 158/500\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3301 - val_loss: 2.6146\n",
      "\n",
      "Epoch 00158: val_loss improved from 2.62240 to 2.61456, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 159/500\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3196 - val_loss: 2.6206\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 2.61456\n",
      "Epoch 160/500\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3206 - val_loss: 2.6014\n",
      "\n",
      "Epoch 00160: val_loss improved from 2.61456 to 2.60142, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 161/500\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3785 - val_loss: 2.6181\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 2.60142\n",
      "Epoch 162/500\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.3454 - val_loss: 2.6311\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 2.60142\n",
      "Epoch 163/500\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3812 - val_loss: 2.6259\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 2.60142\n",
      "Epoch 164/500\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3041 - val_loss: 2.5997\n",
      "\n",
      "Epoch 00164: val_loss improved from 2.60142 to 2.59965, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 165/500\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3461 - val_loss: 2.5921\n",
      "\n",
      "Epoch 00165: val_loss improved from 2.59965 to 2.59209, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 166/500\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2970 - val_loss: 2.5947\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 2.59209\n",
      "Epoch 167/500\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3181 - val_loss: 2.5825\n",
      "\n",
      "Epoch 00167: val_loss improved from 2.59209 to 2.58251, saving model to experimento_ssd300_fault_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3404 - val_loss: 2.5698\n",
      "\n",
      "Epoch 00168: val_loss improved from 2.58251 to 2.56985, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 169/500\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3116 - val_loss: 2.5853\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 2.56985\n",
      "Epoch 170/500\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3500 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 2.56985\n",
      "Epoch 171/500\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2736 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 2.56985\n",
      "Epoch 172/500\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3543 - val_loss: 2.5719\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 2.56985\n",
      "Epoch 173/500\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2950 - val_loss: 2.5573\n",
      "\n",
      "Epoch 00173: val_loss improved from 2.56985 to 2.55734, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 174/500\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2876 - val_loss: 2.5647\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 2.55734\n",
      "Epoch 175/500\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3045 - val_loss: 2.5684\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 2.55734\n",
      "Epoch 176/500\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3047 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 2.55734\n",
      "Epoch 177/500\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3187 - val_loss: 2.5369\n",
      "\n",
      "Epoch 00177: val_loss improved from 2.55734 to 2.53691, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 178/500\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3003 - val_loss: 2.5418\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 2.53691\n",
      "Epoch 179/500\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2856 - val_loss: 2.5507\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 2.53691\n",
      "Epoch 180/500\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2895 - val_loss: 2.5314\n",
      "\n",
      "Epoch 00180: val_loss improved from 2.53691 to 2.53143, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 181/500\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.2750 - val_loss: 2.5598\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 2.53143\n",
      "Epoch 182/500\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2768 - val_loss: 2.5310\n",
      "\n",
      "Epoch 00182: val_loss improved from 2.53143 to 2.53100, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 183/500\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3176 - val_loss: 2.5475\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 2.53100\n",
      "Epoch 184/500\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2267 - val_loss: 2.5595\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 2.53100\n",
      "Epoch 185/500\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3264 - val_loss: 2.5471\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 2.53100\n",
      "Epoch 186/500\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3468 - val_loss: 2.5730\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 2.53100\n",
      "Epoch 187/500\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.3092 - val_loss: 2.5463\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 2.53100\n",
      "Epoch 188/500\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2971 - val_loss: 2.5499\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 2.53100\n",
      "Epoch 189/500\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2848 - val_loss: 2.5662\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 2.53100\n",
      "Epoch 190/500\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2599 - val_loss: 2.5368\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 2.53100\n",
      "Epoch 191/500\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2911 - val_loss: 2.5382\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 2.53100\n",
      "Epoch 192/500\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.2675 - val_loss: 2.5432\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 2.53100\n",
      "Epoch 193/500\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2750 - val_loss: 2.5171\n",
      "\n",
      "Epoch 00193: val_loss improved from 2.53100 to 2.51713, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 194/500\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2869 - val_loss: 2.5373\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 2.51713\n",
      "Epoch 195/500\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2793 - val_loss: 2.5192\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 2.51713\n",
      "Epoch 196/500\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2531 - val_loss: 2.5084\n",
      "\n",
      "Epoch 00196: val_loss improved from 2.51713 to 2.50840, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 197/500\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.3398 - val_loss: 2.5500\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 2.50840\n",
      "Epoch 198/500\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2146 - val_loss: 2.4976\n",
      "\n",
      "Epoch 00198: val_loss improved from 2.50840 to 2.49763, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 199/500\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.2694 - val_loss: 2.5370\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 2.49763\n",
      "Epoch 200/500\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 804ms/step - loss: 2.2821 - val_loss: 2.5114\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 2.49763\n",
      "Epoch 201/500\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 805ms/step - loss: 2.2925 - val_loss: 2.4810\n",
      "\n",
      "Epoch 00201: val_loss improved from 2.49763 to 2.48098, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 202/500\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 804ms/step - loss: 2.2775 - val_loss: 2.5117\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 2.48098\n",
      "Epoch 203/500\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 2.2070 - val_loss: 2.5340\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 2.48098\n",
      "Epoch 204/500\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 811ms/step - loss: 2.3192 - val_loss: 2.5374\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 2.48098\n",
      "Epoch 205/500\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 2.2391 - val_loss: 2.4816\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 2.48098\n",
      "Epoch 206/500\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 815ms/step - loss: 2.2264 - val_loss: 2.5246\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 2.48098\n",
      "Epoch 207/500\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 811ms/step - loss: 2.2346 - val_loss: 2.4970\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 2.48098\n",
      "Epoch 208/500\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 82s 825ms/step - loss: 2.3264 - val_loss: 2.5283\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 2.48098\n",
      "Epoch 209/500\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 811ms/step - loss: 2.1975 - val_loss: 2.5046\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 2.48098\n",
      "Epoch 210/500\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2417 - val_loss: 2.5188\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 2.48098\n",
      "Epoch 211/500\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.3256 - val_loss: 2.5239\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 2.48098\n",
      "Epoch 212/500\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.3239 - val_loss: 2.5052\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 2.48098\n",
      "Epoch 213/500\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2680 - val_loss: 2.5129\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 2.48098\n",
      "Epoch 214/500\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2134 - val_loss: 2.5480\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 2.48098\n",
      "Epoch 215/500\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2342 - val_loss: 2.5272\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 2.48098\n",
      "Epoch 216/500\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 813ms/step - loss: 2.2669 - val_loss: 2.5219\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 2.48098\n",
      "Epoch 217/500\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 825ms/step - loss: 2.2314 - val_loss: 2.5375\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 2.48098\n",
      "Epoch 218/500\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 826ms/step - loss: 2.2534 - val_loss: 2.5319\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 2.48098\n",
      "Epoch 219/500\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 82s 819ms/step - loss: 2.2478 - val_loss: 2.5195\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 2.48098\n",
      "Epoch 220/500\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 84s 837ms/step - loss: 2.2300 - val_loss: 2.5264\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 2.48098\n",
      "Epoch 221/500\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 84s 837ms/step - loss: 2.2123 - val_loss: 2.5198\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 2.48098\n",
      "Epoch 222/500\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 2.2166 - val_loss: 2.5085\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 2.48098\n",
      "Epoch 223/500\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 2.2422 - val_loss: 2.4828\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 2.48098\n",
      "Epoch 224/500\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 84s 837ms/step - loss: 2.2560 - val_loss: 2.5009\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 2.48098\n",
      "Epoch 225/500\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 2.2109 - val_loss: 2.4980\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 2.48098\n",
      "Epoch 226/500\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 82s 818ms/step - loss: 2.2310 - val_loss: 2.4782\n",
      "\n",
      "Epoch 00226: val_loss improved from 2.48098 to 2.47816, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 227/500\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 832ms/step - loss: 2.2518 - val_loss: 2.4627\n",
      "\n",
      "Epoch 00227: val_loss improved from 2.47816 to 2.46269, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 228/500\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 2.2025 - val_loss: 2.4646\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 2.46269\n",
      "Epoch 229/500\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 833ms/step - loss: 2.2603 - val_loss: 2.4577\n",
      "\n",
      "Epoch 00229: val_loss improved from 2.46269 to 2.45775, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 230/500\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 833ms/step - loss: 2.2676 - val_loss: 2.4634\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 2.45775\n",
      "Epoch 231/500\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 2.1934 - val_loss: 2.4829\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 2.45775\n",
      "Epoch 232/500\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 2.1895 - val_loss: 2.4623\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 2.45775\n",
      "Epoch 233/500\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 832ms/step - loss: 2.1922 - val_loss: 2.4841\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 2.45775\n",
      "Epoch 234/500\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 833ms/step - loss: 2.2130 - val_loss: 2.4436\n",
      "\n",
      "Epoch 00234: val_loss improved from 2.45775 to 2.44358, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 235/500\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 2.1743 - val_loss: 2.4906\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 2.44358\n",
      "Epoch 236/500\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 83s 832ms/step - loss: 2.2005 - val_loss: 2.4778\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 2.44358\n",
      "Epoch 237/500\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 82s 818ms/step - loss: 2.2146 - val_loss: 2.4629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00237: val_loss did not improve from 2.44358\n",
      "Epoch 238/500\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2378 - val_loss: 2.4258\n",
      "\n",
      "Epoch 00238: val_loss improved from 2.44358 to 2.42576, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 239/500\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.2562 - val_loss: 2.4473\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 2.42576\n",
      "Epoch 240/500\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1777 - val_loss: 2.4431\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 2.42576\n",
      "Epoch 241/500\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2274 - val_loss: 2.4602\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 2.42576\n",
      "Epoch 242/500\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 81s 805ms/step - loss: 2.2486 - val_loss: 2.4562\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 2.42576\n",
      "Epoch 243/500\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 82s 817ms/step - loss: 2.1823 - val_loss: 2.4786\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 2.42576\n",
      "Epoch 244/500\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 87s 870ms/step - loss: 2.2288 - val_loss: 2.4849\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 2.42576\n",
      "Epoch 245/500\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 85s 852ms/step - loss: 2.1660 - val_loss: 2.4766\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 2.42576\n",
      "Epoch 246/500\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2301 - val_loss: 2.5027\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 2.42576\n",
      "Epoch 247/500\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2135 - val_loss: 2.4650\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 2.42576\n",
      "Epoch 248/500\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2765 - val_loss: 2.4521\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 2.42576\n",
      "Epoch 249/500\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2387 - val_loss: 2.4847\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 2.42576\n",
      "Epoch 250/500\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.1875 - val_loss: 2.4815\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 2.42576\n",
      "Epoch 251/500\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1833 - val_loss: 2.4569\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 2.42576\n",
      "Epoch 252/500\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2238 - val_loss: 2.4827\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 2.42576\n",
      "Epoch 253/500\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2501 - val_loss: 2.4717\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 2.42576\n",
      "Epoch 254/500\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1308 - val_loss: 2.4734\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 2.42576\n",
      "Epoch 255/500\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 2.1565 - val_loss: 2.4662\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 2.42576\n",
      "Epoch 256/500\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.2195 - val_loss: 2.4509\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 2.42576\n",
      "Epoch 257/500\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2483 - val_loss: 2.4529\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 2.42576\n",
      "Epoch 258/500\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.1620 - val_loss: 2.4285\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 2.42576\n",
      "Epoch 259/500\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 801ms/step - loss: 2.1740 - val_loss: 2.4242\n",
      "\n",
      "Epoch 00259: val_loss improved from 2.42576 to 2.42424, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 260/500\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.1539 - val_loss: 2.4161\n",
      "\n",
      "Epoch 00260: val_loss improved from 2.42424 to 2.41611, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 261/500\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1664 - val_loss: 2.4259\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 2.41611\n",
      "Epoch 262/500\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2136 - val_loss: 2.4453\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 2.41611\n",
      "Epoch 263/500\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1044 - val_loss: 2.4816\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 2.41611\n",
      "Epoch 264/500\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1978 - val_loss: 2.4537\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 2.41611\n",
      "Epoch 265/500\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1747 - val_loss: 2.4479\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 2.41611\n",
      "Epoch 266/500\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1925 - val_loss: 2.4660\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 2.41611\n",
      "Epoch 267/500\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1858 - val_loss: 2.4388\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 2.41611\n",
      "Epoch 268/500\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2165 - val_loss: 2.4604\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 2.41611\n",
      "Epoch 269/500\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.2140 - val_loss: 2.4490\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 2.41611\n",
      "Epoch 270/500\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1678 - val_loss: 2.4427\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 2.41611\n",
      "Epoch 271/500\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.2064 - val_loss: 2.4158\n",
      "\n",
      "Epoch 00271: val_loss improved from 2.41611 to 2.41575, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 272/500\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1161 - val_loss: 2.4396\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 2.41575\n",
      "Epoch 273/500\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1986 - val_loss: 2.4483\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 2.41575\n",
      "Epoch 274/500\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1965 - val_loss: 2.4307\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 2.41575\n",
      "Epoch 275/500\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.2041 - val_loss: 2.4547\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 2.41575\n",
      "Epoch 276/500\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.2368 - val_loss: 2.4124\n",
      "\n",
      "Epoch 00276: val_loss improved from 2.41575 to 2.41239, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 277/500\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1827 - val_loss: 2.4110\n",
      "\n",
      "Epoch 00277: val_loss improved from 2.41239 to 2.41095, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 278/500\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1829 - val_loss: 2.4286\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 2.41095\n",
      "Epoch 279/500\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.2048 - val_loss: 2.4266\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 2.41095\n",
      "Epoch 280/500\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1765 - val_loss: 2.4449\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 2.41095\n",
      "Epoch 281/500\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.1752 - val_loss: 2.4267\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 2.41095\n",
      "Epoch 282/500\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1497 - val_loss: 2.4363\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 2.41095\n",
      "Epoch 283/500\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1504 - val_loss: 2.4205\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 2.41095\n",
      "Epoch 284/500\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.1331 - val_loss: 2.4749\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 2.41095\n",
      "Epoch 285/500\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1746 - val_loss: 2.4471\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 2.41095\n",
      "Epoch 286/500\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1463 - val_loss: 2.4463\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 2.41095\n",
      "Epoch 287/500\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.1568 - val_loss: 2.4754\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 2.41095\n",
      "Epoch 288/500\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1094 - val_loss: 2.4033\n",
      "\n",
      "Epoch 00288: val_loss improved from 2.41095 to 2.40333, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 289/500\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1294 - val_loss: 2.4347\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.40333\n",
      "Epoch 290/500\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.1655 - val_loss: 2.4334\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 2.40333\n",
      "Epoch 291/500\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1800 - val_loss: 2.4345\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.40333\n",
      "Epoch 292/500\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1725 - val_loss: 2.4484\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 2.40333\n",
      "Epoch 293/500\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.2019 - val_loss: 2.4093\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.40333\n",
      "Epoch 294/500\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1663 - val_loss: 2.4833\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.40333\n",
      "Epoch 295/500\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1420 - val_loss: 2.4724\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 2.40333\n",
      "Epoch 296/500\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.0923 - val_loss: 2.4685\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.40333\n",
      "Epoch 297/500\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1342 - val_loss: 2.4261\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 2.40333\n",
      "Epoch 298/500\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1697 - val_loss: 2.4211\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.40333\n",
      "Epoch 299/500\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1354 - val_loss: 2.4090\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 2.40333\n",
      "Epoch 300/500\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1326 - val_loss: 2.4623\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.40333\n",
      "Epoch 301/500\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1773 - val_loss: 2.4599\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 2.40333\n",
      "Epoch 302/500\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1958 - val_loss: 2.4428\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 2.40333\n",
      "Epoch 303/500\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0970 - val_loss: 2.4402\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 2.40333\n",
      "Epoch 304/500\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1320 - val_loss: 2.4646\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.40333\n",
      "Epoch 305/500\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1519 - val_loss: 2.4214\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.40333\n",
      "Epoch 306/500\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1758 - val_loss: 2.4445\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.40333\n",
      "Epoch 307/500\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1346 - val_loss: 2.4386\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 2.40333\n",
      "Epoch 308/500\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0994 - val_loss: 2.4430\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.40333\n",
      "Epoch 309/500\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0948 - val_loss: 2.4618\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.40333\n",
      "Epoch 310/500\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1108 - val_loss: 2.4125\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.40333\n",
      "Epoch 311/500\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1230 - val_loss: 2.4152\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.40333\n",
      "Epoch 312/500\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1885 - val_loss: 2.3989\n",
      "\n",
      "Epoch 00312: val_loss improved from 2.40333 to 2.39892, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 313/500\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1826 - val_loss: 2.4245\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.39892\n",
      "Epoch 314/500\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1490 - val_loss: 2.4514\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 2.39892\n",
      "Epoch 315/500\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1385 - val_loss: 2.4354\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 2.39892\n",
      "Epoch 316/500\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1267 - val_loss: 2.4204\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 2.39892\n",
      "Epoch 317/500\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1377 - val_loss: 2.3919\n",
      "\n",
      "Epoch 00317: val_loss improved from 2.39892 to 2.39192, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 318/500\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1597 - val_loss: 2.4013\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 2.39192\n",
      "Epoch 319/500\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1371 - val_loss: 2.4382\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 2.39192\n",
      "Epoch 320/500\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1655 - val_loss: 2.3971\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 2.39192\n",
      "Epoch 321/500\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1480 - val_loss: 2.3843\n",
      "\n",
      "Epoch 00321: val_loss improved from 2.39192 to 2.38430, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 322/500\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1041 - val_loss: 2.4188\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 2.38430\n",
      "Epoch 323/500\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1651 - val_loss: 2.3858\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 2.38430\n",
      "Epoch 324/500\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1550 - val_loss: 2.3975\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 2.38430\n",
      "Epoch 325/500\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1363 - val_loss: 2.4203\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 2.38430\n",
      "Epoch 326/500\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1205 - val_loss: 2.4071\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 2.38430\n",
      "Epoch 327/500\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0460 - val_loss: 2.4163\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 2.38430\n",
      "Epoch 328/500\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1368 - val_loss: 2.4043\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 2.38430\n",
      "Epoch 329/500\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1165 - val_loss: 2.4102\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 2.38430\n",
      "Epoch 330/500\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0698 - val_loss: 2.4503\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 2.38430\n",
      "Epoch 331/500\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1698 - val_loss: 2.3874\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 2.38430\n",
      "Epoch 332/500\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0500 - val_loss: 2.4484\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 2.38430\n",
      "Epoch 333/500\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1160 - val_loss: 2.4091\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 2.38430\n",
      "Epoch 334/500\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1460 - val_loss: 2.4595\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 2.38430\n",
      "Epoch 335/500\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1175 - val_loss: 2.4163\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 2.38430\n",
      "Epoch 336/500\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1029 - val_loss: 2.4175\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 2.38430\n",
      "Epoch 337/500\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1533 - val_loss: 2.4147\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 2.38430\n",
      "Epoch 338/500\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1118 - val_loss: 2.4363\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 2.38430\n",
      "Epoch 339/500\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1367 - val_loss: 2.4138\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 2.38430\n",
      "Epoch 340/500\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0941 - val_loss: 2.4105\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 2.38430\n",
      "Epoch 341/500\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0905 - val_loss: 2.4222\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 2.38430\n",
      "Epoch 342/500\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0956 - val_loss: 2.4531\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 2.38430\n",
      "Epoch 343/500\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1527 - val_loss: 2.4406\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 2.38430\n",
      "Epoch 344/500\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1195 - val_loss: 2.4184\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 2.38430\n",
      "Epoch 345/500\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1247 - val_loss: 2.3930\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 2.38430\n",
      "Epoch 346/500\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0853 - val_loss: 2.4446\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 2.38430\n",
      "Epoch 347/500\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0962 - val_loss: 2.3987\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 2.38430\n",
      "Epoch 348/500\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0868 - val_loss: 2.4302\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 2.38430\n",
      "Epoch 349/500\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1354 - val_loss: 2.4145\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 2.38430\n",
      "Epoch 350/500\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0808 - val_loss: 2.4016\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 2.38430\n",
      "Epoch 351/500\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0929 - val_loss: 2.4298\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 2.38430\n",
      "Epoch 352/500\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1178 - val_loss: 2.3901\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 2.38430\n",
      "Epoch 353/500\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0798 - val_loss: 2.4365\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 2.38430\n",
      "Epoch 354/500\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0993 - val_loss: 2.4296\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 2.38430\n",
      "Epoch 355/500\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0661 - val_loss: 2.4054\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 2.38430\n",
      "Epoch 356/500\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0964 - val_loss: 2.4211\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 2.38430\n",
      "Epoch 357/500\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1526 - val_loss: 2.4048\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 2.38430\n",
      "Epoch 358/500\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0620 - val_loss: 2.4042\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 2.38430\n",
      "Epoch 359/500\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0800 - val_loss: 2.4167\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 2.38430\n",
      "Epoch 360/500\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1386 - val_loss: 2.4166\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 2.38430\n",
      "Epoch 361/500\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0717 - val_loss: 2.3937\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 2.38430\n",
      "Epoch 362/500\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1056 - val_loss: 2.3814\n",
      "\n",
      "Epoch 00362: val_loss improved from 2.38430 to 2.38138, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 363/500\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0884 - val_loss: 2.3623\n",
      "\n",
      "Epoch 00363: val_loss improved from 2.38138 to 2.36234, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 364/500\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0678 - val_loss: 2.3943\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 2.36234\n",
      "Epoch 365/500\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0853 - val_loss: 2.4385\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 2.36234\n",
      "Epoch 366/500\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1190 - val_loss: 2.4279\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 2.36234\n",
      "Epoch 367/500\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1034 - val_loss: 2.3857\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 2.36234\n",
      "Epoch 368/500\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0699 - val_loss: 2.4007\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 2.36234\n",
      "Epoch 369/500\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1649 - val_loss: 2.3795\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 2.36234\n",
      "Epoch 370/500\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0986 - val_loss: 2.3778\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 2.36234\n",
      "Epoch 371/500\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1006 - val_loss: 2.4018\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 2.36234\n",
      "Epoch 372/500\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0778 - val_loss: 2.3997\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 2.36234\n",
      "Epoch 373/500\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0916 - val_loss: 2.4090\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 2.36234\n",
      "Epoch 374/500\n",
      "\n",
      "Epoch 00374: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0937 - val_loss: 2.4017\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 2.36234\n",
      "Epoch 375/500\n",
      "\n",
      "Epoch 00375: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0926 - val_loss: 2.3936\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 2.36234\n",
      "Epoch 376/500\n",
      "\n",
      "Epoch 00376: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1085 - val_loss: 2.4056\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 2.36234\n",
      "Epoch 377/500\n",
      "\n",
      "Epoch 00377: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0807 - val_loss: 2.4472\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 2.36234\n",
      "Epoch 378/500\n",
      "\n",
      "Epoch 00378: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0767 - val_loss: 2.3985\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 2.36234\n",
      "Epoch 379/500\n",
      "\n",
      "Epoch 00379: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1006 - val_loss: 2.3763\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 2.36234\n",
      "Epoch 380/500\n",
      "\n",
      "Epoch 00380: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0999 - val_loss: 2.3724\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 2.36234\n",
      "Epoch 381/500\n",
      "\n",
      "Epoch 00381: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0636 - val_loss: 2.3865\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 2.36234\n",
      "Epoch 382/500\n",
      "\n",
      "Epoch 00382: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9868 - val_loss: 2.3687\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 2.36234\n",
      "Epoch 383/500\n",
      "\n",
      "Epoch 00383: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0264 - val_loss: 2.3919\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 2.36234\n",
      "Epoch 384/500\n",
      "\n",
      "Epoch 00384: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1080 - val_loss: 2.3729\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 2.36234\n",
      "Epoch 385/500\n",
      "\n",
      "Epoch 00385: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1055 - val_loss: 2.3540\n",
      "\n",
      "Epoch 00385: val_loss improved from 2.36234 to 2.35402, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 386/500\n",
      "\n",
      "Epoch 00386: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0652 - val_loss: 2.3670\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 2.35402\n",
      "Epoch 387/500\n",
      "\n",
      "Epoch 00387: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1103 - val_loss: 2.3755\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 2.35402\n",
      "Epoch 388/500\n",
      "\n",
      "Epoch 00388: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0526 - val_loss: 2.3800\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 2.35402\n",
      "Epoch 389/500\n",
      "\n",
      "Epoch 00389: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0536 - val_loss: 2.3885\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 2.35402\n",
      "Epoch 390/500\n",
      "\n",
      "Epoch 00390: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1088 - val_loss: 2.3599\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 2.35402\n",
      "Epoch 391/500\n",
      "\n",
      "Epoch 00391: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0575 - val_loss: 2.3714\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 2.35402\n",
      "Epoch 392/500\n",
      "\n",
      "Epoch 00392: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0073 - val_loss: 2.4156\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 2.35402\n",
      "Epoch 393/500\n",
      "\n",
      "Epoch 00393: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1487 - val_loss: 2.3745\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 2.35402\n",
      "Epoch 394/500\n",
      "\n",
      "Epoch 00394: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0446 - val_loss: 2.3935\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 2.35402\n",
      "Epoch 395/500\n",
      "\n",
      "Epoch 00395: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1099 - val_loss: 2.4126\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 2.35402\n",
      "Epoch 396/500\n",
      "\n",
      "Epoch 00396: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0329 - val_loss: 2.4481\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 2.35402\n",
      "Epoch 397/500\n",
      "\n",
      "Epoch 00397: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0798 - val_loss: 2.3902\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 2.35402\n",
      "Epoch 398/500\n",
      "\n",
      "Epoch 00398: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.1269 - val_loss: 2.4099\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 2.35402\n",
      "Epoch 399/500\n",
      "\n",
      "Epoch 00399: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0647 - val_loss: 2.3668\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 2.35402\n",
      "Epoch 400/500\n",
      "\n",
      "Epoch 00400: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0623 - val_loss: 2.3641\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 2.35402\n",
      "Epoch 401/500\n",
      "\n",
      "Epoch 00401: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0806 - val_loss: 2.4077\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 2.35402\n",
      "Epoch 402/500\n",
      "\n",
      "Epoch 00402: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0625 - val_loss: 2.3878\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 2.35402\n",
      "Epoch 403/500\n",
      "\n",
      "Epoch 00403: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0204 - val_loss: 2.3818\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 2.35402\n",
      "Epoch 404/500\n",
      "\n",
      "Epoch 00404: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0725 - val_loss: 2.4053\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 2.35402\n",
      "Epoch 405/500\n",
      "\n",
      "Epoch 00405: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0589 - val_loss: 2.4102\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 2.35402\n",
      "Epoch 406/500\n",
      "\n",
      "Epoch 00406: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0186 - val_loss: 2.3415\n",
      "\n",
      "Epoch 00406: val_loss improved from 2.35402 to 2.34146, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 407/500\n",
      "\n",
      "Epoch 00407: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0659 - val_loss: 2.3922\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 2.34146\n",
      "Epoch 408/500\n",
      "\n",
      "Epoch 00408: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0959 - val_loss: 2.3671\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 2.34146\n",
      "Epoch 409/500\n",
      "\n",
      "Epoch 00409: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0579 - val_loss: 2.4155\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 2.34146\n",
      "Epoch 410/500\n",
      "\n",
      "Epoch 00410: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0830 - val_loss: 2.3769\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 2.34146\n",
      "Epoch 411/500\n",
      "\n",
      "Epoch 00411: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0422 - val_loss: 2.4380\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 2.34146\n",
      "Epoch 412/500\n",
      "\n",
      "Epoch 00412: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0299 - val_loss: 2.3743\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 2.34146\n",
      "Epoch 413/500\n",
      "\n",
      "Epoch 00413: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0745 - val_loss: 2.4274\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 2.34146\n",
      "Epoch 414/500\n",
      "\n",
      "Epoch 00414: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.1003 - val_loss: 2.3616\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 2.34146\n",
      "Epoch 415/500\n",
      "\n",
      "Epoch 00415: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0427 - val_loss: 2.3785\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 2.34146\n",
      "Epoch 416/500\n",
      "\n",
      "Epoch 00416: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0771 - val_loss: 2.3834\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 2.34146\n",
      "Epoch 417/500\n",
      "\n",
      "Epoch 00417: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0350 - val_loss: 2.3746\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 2.34146\n",
      "Epoch 418/500\n",
      "\n",
      "Epoch 00418: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0556 - val_loss: 2.3677\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 2.34146\n",
      "Epoch 419/500\n",
      "\n",
      "Epoch 00419: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.1044 - val_loss: 2.3601\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 2.34146\n",
      "Epoch 420/500\n",
      "\n",
      "Epoch 00420: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0146 - val_loss: 2.3894\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 2.34146\n",
      "Epoch 421/500\n",
      "\n",
      "Epoch 00421: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0476 - val_loss: 2.3624\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 2.34146\n",
      "Epoch 422/500\n",
      "\n",
      "Epoch 00422: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0478 - val_loss: 2.3906\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 2.34146\n",
      "Epoch 423/500\n",
      "\n",
      "Epoch 00423: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0872 - val_loss: 2.3948\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 2.34146\n",
      "Epoch 424/500\n",
      "\n",
      "Epoch 00424: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0461 - val_loss: 2.3858\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 2.34146\n",
      "Epoch 425/500\n",
      "\n",
      "Epoch 00425: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0589 - val_loss: 2.4122\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 2.34146\n",
      "Epoch 426/500\n",
      "\n",
      "Epoch 00426: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0172 - val_loss: 2.3670\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 2.34146\n",
      "Epoch 427/500\n",
      "\n",
      "Epoch 00427: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0098 - val_loss: 2.3985\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 2.34146\n",
      "Epoch 428/500\n",
      "\n",
      "Epoch 00428: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0527 - val_loss: 2.3992\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 2.34146\n",
      "Epoch 429/500\n",
      "\n",
      "Epoch 00429: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0470 - val_loss: 2.4607\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 2.34146\n",
      "Epoch 430/500\n",
      "\n",
      "Epoch 00430: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0599 - val_loss: 2.4135\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 2.34146\n",
      "Epoch 431/500\n",
      "\n",
      "Epoch 00431: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0177 - val_loss: 2.3874\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 2.34146\n",
      "Epoch 432/500\n",
      "\n",
      "Epoch 00432: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9960 - val_loss: 2.4020\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 2.34146\n",
      "Epoch 433/500\n",
      "\n",
      "Epoch 00433: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0111 - val_loss: 2.3511\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 2.34146\n",
      "Epoch 434/500\n",
      "\n",
      "Epoch 00434: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0170 - val_loss: 2.3787\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 2.34146\n",
      "Epoch 435/500\n",
      "\n",
      "Epoch 00435: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9859 - val_loss: 2.3683\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 2.34146\n",
      "Epoch 436/500\n",
      "\n",
      "Epoch 00436: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0651 - val_loss: 2.3521\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 2.34146\n",
      "Epoch 437/500\n",
      "\n",
      "Epoch 00437: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0509 - val_loss: 2.3714\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 2.34146\n",
      "Epoch 438/500\n",
      "\n",
      "Epoch 00438: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0418 - val_loss: 2.3868\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 2.34146\n",
      "Epoch 439/500\n",
      "\n",
      "Epoch 00439: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0409 - val_loss: 2.3806\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 2.34146\n",
      "Epoch 440/500\n",
      "\n",
      "Epoch 00440: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.1010 - val_loss: 2.3676\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 2.34146\n",
      "Epoch 441/500\n",
      "\n",
      "Epoch 00441: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0553 - val_loss: 2.4117\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 2.34146\n",
      "Epoch 442/500\n",
      "\n",
      "Epoch 00442: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 1.9936 - val_loss: 2.4315\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 2.34146\n",
      "Epoch 443/500\n",
      "\n",
      "Epoch 00443: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0162 - val_loss: 2.4066\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 2.34146\n",
      "Epoch 444/500\n",
      "\n",
      "Epoch 00444: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0278 - val_loss: 2.4046\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 2.34146\n",
      "Epoch 445/500\n",
      "\n",
      "Epoch 00445: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0602 - val_loss: 2.3750\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 2.34146\n",
      "Epoch 446/500\n",
      "\n",
      "Epoch 00446: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0345 - val_loss: 2.3787\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 2.34146\n",
      "Epoch 447/500\n",
      "\n",
      "Epoch 00447: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0533 - val_loss: 2.3742\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 2.34146\n",
      "Epoch 448/500\n",
      "\n",
      "Epoch 00448: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0464 - val_loss: 2.3607\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 2.34146\n",
      "Epoch 449/500\n",
      "\n",
      "Epoch 00449: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0469 - val_loss: 2.3640\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 2.34146\n",
      "Epoch 450/500\n",
      "\n",
      "Epoch 00450: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0163 - val_loss: 2.4275\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 2.34146\n",
      "Epoch 451/500\n",
      "\n",
      "Epoch 00451: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0045 - val_loss: 2.3684\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 2.34146\n",
      "Epoch 452/500\n",
      "\n",
      "Epoch 00452: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0544 - val_loss: 2.3581\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 2.34146\n",
      "Epoch 453/500\n",
      "\n",
      "Epoch 00453: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0316 - val_loss: 2.3709\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 2.34146\n",
      "Epoch 454/500\n",
      "\n",
      "Epoch 00454: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0651 - val_loss: 2.3356\n",
      "\n",
      "Epoch 00454: val_loss improved from 2.34146 to 2.33563, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 455/500\n",
      "\n",
      "Epoch 00455: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0227 - val_loss: 2.3851\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 2.33563\n",
      "Epoch 456/500\n",
      "\n",
      "Epoch 00456: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0243 - val_loss: 2.3436\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 2.33563\n",
      "Epoch 457/500\n",
      "\n",
      "Epoch 00457: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0296 - val_loss: 2.4156\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 2.33563\n",
      "Epoch 458/500\n",
      "\n",
      "Epoch 00458: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9851 - val_loss: 2.3550\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 2.33563\n",
      "Epoch 459/500\n",
      "\n",
      "Epoch 00459: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0508 - val_loss: 2.3610\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 2.33563\n",
      "Epoch 460/500\n",
      "\n",
      "Epoch 00460: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0041 - val_loss: 2.4261\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 2.33563\n",
      "Epoch 461/500\n",
      "\n",
      "Epoch 00461: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0278 - val_loss: 2.3630\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 2.33563\n",
      "Epoch 462/500\n",
      "\n",
      "Epoch 00462: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9905 - val_loss: 2.3738\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 2.33563\n",
      "Epoch 463/500\n",
      "\n",
      "Epoch 00463: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0774 - val_loss: 2.3582\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 2.33563\n",
      "Epoch 464/500\n",
      "\n",
      "Epoch 00464: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9975 - val_loss: 2.3427\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 2.33563\n",
      "Epoch 465/500\n",
      "\n",
      "Epoch 00465: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0039 - val_loss: 2.4340\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 2.33563\n",
      "Epoch 466/500\n",
      "\n",
      "Epoch 00466: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0650 - val_loss: 2.3641\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 2.33563\n",
      "Epoch 467/500\n",
      "\n",
      "Epoch 00467: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9773 - val_loss: 2.3502\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 2.33563\n",
      "Epoch 468/500\n",
      "\n",
      "Epoch 00468: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9900 - val_loss: 2.3671\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 2.33563\n",
      "Epoch 469/500\n",
      "\n",
      "Epoch 00469: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0433 - val_loss: 2.4299\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 2.33563\n",
      "Epoch 470/500\n",
      "\n",
      "Epoch 00470: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0096 - val_loss: 2.3356\n",
      "\n",
      "Epoch 00470: val_loss improved from 2.33563 to 2.33556, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 471/500\n",
      "\n",
      "Epoch 00471: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0814 - val_loss: 2.4134\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 2.33556\n",
      "Epoch 472/500\n",
      "\n",
      "Epoch 00472: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0282 - val_loss: 2.3833\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 2.33556\n",
      "Epoch 473/500\n",
      "\n",
      "Epoch 00473: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9912 - val_loss: 2.3809\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 2.33556\n",
      "Epoch 474/500\n",
      "\n",
      "Epoch 00474: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0636 - val_loss: 2.3998\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 2.33556\n",
      "Epoch 475/500\n",
      "\n",
      "Epoch 00475: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9840 - val_loss: 2.3530\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 2.33556\n",
      "Epoch 476/500\n",
      "\n",
      "Epoch 00476: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0183 - val_loss: 2.4219\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 2.33556\n",
      "Epoch 477/500\n",
      "\n",
      "Epoch 00477: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9861 - val_loss: 2.3589\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 2.33556\n",
      "Epoch 478/500\n",
      "\n",
      "Epoch 00478: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0277 - val_loss: 2.3678\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 2.33556\n",
      "Epoch 479/500\n",
      "\n",
      "Epoch 00479: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 796ms/step - loss: 2.0421 - val_loss: 2.3922\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 2.33556\n",
      "Epoch 480/500\n",
      "\n",
      "Epoch 00480: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9588 - val_loss: 2.3798\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 2.33556\n",
      "Epoch 481/500\n",
      "\n",
      "Epoch 00481: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0262 - val_loss: 2.3859\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 2.33556\n",
      "Epoch 482/500\n",
      "\n",
      "Epoch 00482: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9900 - val_loss: 2.3502\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 2.33556\n",
      "Epoch 483/500\n",
      "\n",
      "Epoch 00483: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9932 - val_loss: 2.3712\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 2.33556\n",
      "Epoch 484/500\n",
      "\n",
      "Epoch 00484: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0029 - val_loss: 2.3610\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 2.33556\n",
      "Epoch 485/500\n",
      "\n",
      "Epoch 00485: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0292 - val_loss: 2.3485\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 2.33556\n",
      "Epoch 486/500\n",
      "\n",
      "Epoch 00486: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0036 - val_loss: 2.3521\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 2.33556\n",
      "Epoch 487/500\n",
      "\n",
      "Epoch 00487: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0304 - val_loss: 2.3897\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 2.33556\n",
      "Epoch 488/500\n",
      "\n",
      "Epoch 00488: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 2.0249 - val_loss: 2.3887\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 2.33556\n",
      "Epoch 489/500\n",
      "\n",
      "Epoch 00489: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0184 - val_loss: 2.4082\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 2.33556\n",
      "Epoch 490/500\n",
      "\n",
      "Epoch 00490: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0207 - val_loss: 2.4115\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 2.33556\n",
      "Epoch 491/500\n",
      "\n",
      "Epoch 00491: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0193 - val_loss: 2.3330\n",
      "\n",
      "Epoch 00491: val_loss improved from 2.33556 to 2.33299, saving model to experimento_ssd300_fault_1.h5\n",
      "Epoch 492/500\n",
      "\n",
      "Epoch 00492: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0064 - val_loss: 2.3920\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 2.33299\n",
      "Epoch 493/500\n",
      "\n",
      "Epoch 00493: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 2.0322 - val_loss: 2.3671\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 2.33299\n",
      "Epoch 494/500\n",
      "\n",
      "Epoch 00494: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9830 - val_loss: 2.3444\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 2.33299\n",
      "Epoch 495/500\n",
      "\n",
      "Epoch 00495: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 2.0090 - val_loss: 2.3845\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 2.33299\n",
      "Epoch 496/500\n",
      "\n",
      "Epoch 00496: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 800ms/step - loss: 1.9609 - val_loss: 2.3364\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 2.33299\n",
      "Epoch 497/500\n",
      "\n",
      "Epoch 00497: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 1.9617 - val_loss: 2.3641\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 2.33299\n",
      "Epoch 498/500\n",
      "\n",
      "Epoch 00498: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9880 - val_loss: 2.3624\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 2.33299\n",
      "Epoch 499/500\n",
      "\n",
      "Epoch 00499: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 1.9825 - val_loss: 2.3824\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 2.33299\n",
      "Epoch 500/500\n",
      "\n",
      "Epoch 00500: LearningRateScheduler setting learning rate to 1e-05.\n",
      "100/100 [==============================] - 80s 797ms/step - loss: 2.0526 - val_loss: 2.3589\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 2.33299\n"
     ]
    }
   ],
   "source": [
    "#ENTRENAMIENTO DE MODELO\n",
    "#####################################################################\n",
    "#  Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "######################################################################\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "\n",
    "\n",
    "\n",
    "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
    "classes = ['background' ] + labels\n",
    "\n",
    "train_dataset.parse_xml(images_dirs= [config['train']['train_image_folder']],\n",
    "                        image_set_filenames=[config['train']['train_image_set_filename']],\n",
    "                        annotations_dirs=[config['train']['train_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = classes, \n",
    "                        #include_classes= [1],\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs= [config['test']['test_image_folder']],\n",
    "                        image_set_filenames=[config['test']['test_image_set_filename']],\n",
    "                        annotations_dirs=[config['test']['test_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = classes, \n",
    "                        #include_classes=[1],\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "#########################\n",
    "# 3: Set the batch size.\n",
    "#########################\n",
    "batch_size = config['train']['batch_size'] # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "##########################\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "##########################\n",
    "# For the training generator:\n",
    "\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "######################################3\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "#########################################\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "if config['model']['backend'] == 'ssd300':\n",
    "    predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                       model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
    "    ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                        img_width=img_width,\n",
    "                                        n_classes=n_classes,\n",
    "                                        predictor_sizes=predictor_sizes,\n",
    "                                        scales=scales,\n",
    "                                        aspect_ratios_per_layer=aspect_ratios,\n",
    "                                        two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                        steps=steps,\n",
    "                                        offsets=offsets,\n",
    "                                        clip_boxes=clip_boxes,\n",
    "                                        variances=variances,\n",
    "                                        matching_type='multi',\n",
    "                                        pos_iou_threshold=0.5,\n",
    "                                        neg_iou_limit=0.5,\n",
    "                                        normalize_coords=normalize_coords)\n",
    "\n",
    "elif config['model']['backend'] == 'ssd7':\n",
    "    predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n",
    "                       model.get_layer('classes5').output_shape[1:3],\n",
    "                       model.get_layer('classes6').output_shape[1:3],\n",
    "                       model.get_layer('classes7').output_shape[1:3]]\n",
    "    ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                img_width=img_width,\n",
    "                                n_classes=n_classes,\n",
    "                                predictor_sizes=predictor_sizes,\n",
    "                                scales=scales,\n",
    "                                aspect_ratios_global=aspect_ratios,\n",
    "                                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                steps=steps,\n",
    "                                offsets=offsets,\n",
    "                                clip_boxes=clip_boxes,\n",
    "                                variances=variances,\n",
    "                                matching_type='multi',\n",
    "                                pos_iou_threshold=0.5,\n",
    "                                neg_iou_limit=0.3,\n",
    "                                normalize_coords=normalize_coords)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "data_augmentation_chain = DataAugmentationVariableInputSize(resize_height = img_height,\n",
    "                                                            resize_width = img_width,\n",
    "                                                            random_brightness=(-48, 48, 0.5),\n",
    "                                                            random_contrast=(0.5, 1.8, 0.5),\n",
    "                                                            random_saturation=(0.5, 1.8, 0.5),\n",
    "                                                            random_hue=(18, 0.5),\n",
    "                                                            random_flip=0.5,\n",
    "                                                            n_trials_max=3,\n",
    "                                                            clip_boxes=True,\n",
    "                                                            overlap_criterion='area',\n",
    "                                                            bounds_box_filter=(0.3, 1.0),\n",
    "                                                            bounds_validator=(0.5, 1.0),\n",
    "                                                            n_boxes_min=1,\n",
    "                                                            background=(0,0,0))\n",
    "#######################\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "#######################\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=  [data_augmentation_chain],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Summary instance training\n",
    "category_train_list = []\n",
    "for image_label in train_dataset.labels:\n",
    "    category_train_list += [i[0] for i in image_label]\n",
    "summary_category_training = {train_dataset.classes[i]: category_train_list.count(i) for i in list(set(category_train_list))}\n",
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))\n",
    "\n",
    "\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "# Define model callbacks.\n",
    "#########################\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath= config['train']['saved_weights_name'],\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "#model_checkpoint.best =\n",
    "\n",
    "csv_logger = CSVLogger(filename='log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan]\n",
    "\n",
    "\n",
    "\n",
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 500 #config['train']['nb_epochs']\n",
    "steps_per_epoch = 100\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size*10),\n",
    "                              initial_epoch=initial_epoch,\n",
    "                              verbose = 1 if config['train']['debug'] else 2)\n",
    "\n",
    "history_path = config['train']['saved_weights_name'].split('.')[0] + '_history'\n",
    "\n",
    "np.save(history_path, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', '1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimento_ssd300_fault_1.h5\n"
     ]
    }
   ],
   "source": [
    "#Graficar aprendizaje\n",
    "\n",
    "history_path =config['train']['saved_weights_name'].split('.')[0] + '_history'\n",
    "\n",
    "hist_load = np.load(history_path + '.npy',allow_pickle=True).item()\n",
    "\n",
    "print(hist_load.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist_load['loss'])\n",
    "plt.plot(hist_load['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.ylim((0, 10))  \n",
    "plt.show()\n",
    "\n",
    "print(config['train']['saved_weights_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|██████████| 33/33 [00:00<00:00, 112.45it/s]\n",
      "Processing image set 'test.txt': 100%|██████████| 2/2 [00:00<00:00, 57.78it/s]\n",
      "Number of images in the evaluation dataset: 2\n",
      "\n",
      "Producing predictions batch-wise: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Matching predictions to ground truth, class 1/1.: 100%|██████████| 400/400 [00:00<00:00, 9288.89it/s]\n",
      "Computing precisions and recalls, class 1/1\n",
      "Computing average precision, class 1/1\n",
      "400 instances of class 1 with average precision: 0.7948\n",
      "mAP using the weighted average of precisions among classes: 0.7948\n",
      "mAP: 0.7948\n",
      "1             AP    0.795\n",
      "\n",
      "              mAP   0.795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_path = 'config_300_fault_1.json'\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "    \n",
    "model_mode = 'training'\n",
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = config['train']['saved_weights_name']\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "    \n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "\n",
    "\n",
    "\n",
    "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
    "classes = ['background' ] + labels\n",
    "\n",
    "train_dataset.parse_xml(images_dirs= [config['train']['train_image_folder']],\n",
    "                        image_set_filenames=[config['train']['train_image_set_filename']],\n",
    "                        annotations_dirs=[config['train']['train_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = ['background', 'panel', 'cell'], \n",
    "                        #include_classes=classes,\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs= [config['test']['test_image_folder']],\n",
    "                        image_set_filenames=[config['test']['test_image_set_filename']],\n",
    "                        annotations_dirs=[config['test']['test_annot_folder']],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        #classes = ['background', 'panel', 'cell'], \n",
    "                        #include_classes=classes,\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "#########################\n",
    "# 3: Set the batch size.\n",
    "#########################\n",
    "batch_size = config['train']['batch_size'] # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluator = Evaluator(model=model,\n",
    "                      n_classes=n_classes,\n",
    "                      data_generator=val_dataset,\n",
    "                      model_mode='training')\n",
    "\n",
    "results = evaluator(img_height=img_height,\n",
    "                    img_width=img_width,\n",
    "                    batch_size=4,\n",
    "                    data_generator_mode='resize',\n",
    "                    round_confidences=False,\n",
    "                    matching_iou_threshold=0.5,\n",
    "                    border_pixels='include',\n",
    "                    sorting_algorithm='quicksort',\n",
    "                    average_precision_mode='sample',\n",
    "                    num_recall_points=11,\n",
    "                    ignore_neutral_boxes=True,\n",
    "                    return_precisions=True,\n",
    "                    return_recalls=True,\n",
    "                    return_average_precisions=True,\n",
    "                    verbose=True)\n",
    "\n",
    "mean_average_precision, average_precisions, precisions, recalls = results\n",
    "total_instances = []\n",
    "precisions = []\n",
    "\n",
    "for i in range(1, len(average_precisions)):\n",
    "    \n",
    "    print('{:.0f} instances of class'.format(len(recalls[i])),\n",
    "          classes[i], 'with average precision: {:.4f}'.format(average_precisions[i]))\n",
    "    total_instances.append(len(recalls[i]))\n",
    "    precisions.append(average_precisions[i])\n",
    "\n",
    "if sum(total_instances) == 0:\n",
    "    \n",
    "    print('No test instances found.')\n",
    "\n",
    "else:\n",
    "\n",
    "    print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
    "    print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))\n",
    "\n",
    "    for i in range(1, len(average_precisions)):\n",
    "        print(\"{:<14}{:<6}{}\".format(classes[i], 'AP', round(average_precisions[i], 3)))\n",
    "    print()\n",
    "    print(\"{:<14}{:<6}{}\".format('','mAP', round(mean_average_precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceil(val_dataset_size/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar nuevamente el modelo desde los pesos.\n",
    "Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on: \t{'1': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imageio import imread\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "config_path = 'config_300_fault_1.json'\n",
    "input_path = ['fault_jpg_1/']\n",
    "output_path = 'result_ssd300_fault_1/'\n",
    "\n",
    "with open(config_path) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "makedirs(output_path)\n",
    "###############################\n",
    "#   Parse the annotations\n",
    "###############################\n",
    "score_threshold = 0.25\n",
    "score_threshold_iou = 0.5\n",
    "labels = config['model']['labels']\n",
    "categories = {}\n",
    "#categories = {\"Razor\": 1, \"Gun\": 2, \"Knife\": 3, \"Shuriken\": 4} #la categoría 0 es la background\n",
    "for i in range(len(labels)): categories[labels[i]] = i+1\n",
    "print('\\nTraining on: \\t' + str(categories) + '\\n')\n",
    "\n",
    "img_height = config['model']['input'] # Height of the model input images\n",
    "img_width = config['model']['input'] # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "n_classes = len(labels) # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "classes = ['background'] + labels\n",
    "\n",
    "model_mode = 'training'\n",
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = config['train']['saved_weights_name']\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo Total: 1.982\n",
      "Tiempo promedio por imagen: 0.079\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for inp in input_path:\n",
    "    if os.path.isdir(inp):\n",
    "        for inp_file in os.listdir(inp):\n",
    "            image_paths += [inp + inp_file]\n",
    "    else:\n",
    "        image_paths += [inp]\n",
    "\n",
    "image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
    "times = []\n",
    "\n",
    "\n",
    "for img_path in image_paths:\n",
    "    orig_images = [] # Store the images here.\n",
    "    input_images = [] # Store resized versions of the images here.\n",
    "    #print(img_path)\n",
    "\n",
    "    # preprocess image for network\n",
    "    orig_images.append(imread(img_path))\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "    input_images.append(img)\n",
    "    input_images = np.array(input_images)\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(input_images)\n",
    "    y_pred_decoded = decode_detections(y_pred,\n",
    "                               confidence_thresh=score_threshold,\n",
    "                               iou_threshold=score_threshold_iou,\n",
    "                               top_k=200,\n",
    "                               normalize_coords=True,\n",
    "                               img_height=img_height,\n",
    "                               img_width=img_width)\n",
    "\n",
    "\n",
    "    #print(\"processing time: \", time.time() - start)\n",
    "    times.append(time.time() - start)\n",
    "    # correct for image scale\n",
    "\n",
    "    # visualize detections\n",
    "    # Set the colors for the bounding boxes\n",
    "    colors = plt.cm.brg(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(orig_images[0],cmap = 'gray')\n",
    "\n",
    "    current_axis = plt.gca()\n",
    "    #print(y_pred)\n",
    "    for box in y_pred_decoded[0]:\n",
    "        # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "\n",
    "        xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "        ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "        xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "        ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "\n",
    "        color = colors[int(box[0])]\n",
    "        label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "        current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "        current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.axis('off')\n",
    "    save_path = output_path + img_path.split('/')[-1]\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "file = open(output_path + 'time.txt','w')\n",
    "\n",
    "file.write('Tiempo promedio:' + str(np.mean(times)))\n",
    "\n",
    "file.close()\n",
    "print('Tiempo Total: {:.3f}'.format(np.sum(times)))\n",
    "print('Tiempo promedio por imagen: {:.3f}'.format(np.mean(times)))\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summary instance training\n",
    "category_train_list = []\n",
    "for image_label in train_dataset.labels:\n",
    "    category_train_list += [i[0] for i in train_dataset.labels[0]]\n",
    "summary_category_training = {train_dataset.classes[i]: category_train_list.count(i) for i in list(set(category_train_list))}\n",
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 99\n"
     ]
    }
   ],
   "source": [
    "for i in summary_category_training.keys():\n",
    "     print(i, ': {:.0f}'.format(summary_category_training[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
